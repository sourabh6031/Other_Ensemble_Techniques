{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fad8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOURABH\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\SOURABH\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe68ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('booking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94b9161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff72e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_original['booking_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93421660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_original.drop(columns='booking_status',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ca93c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>67.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  no_of_adults  no_of_children  no_of_weekend_nights  no_of_week_nights  \\\n",
       "0   0             2               0                     0                  2   \n",
       "1   1             2               0                     1                  2   \n",
       "2   2             2               0                     0                  1   \n",
       "3   3             1               0                     0                  2   \n",
       "4   4             2               0                     1                  0   \n",
       "\n",
       "   type_of_meal_plan  required_car_parking_space  room_type_reserved  \\\n",
       "0                  1                           0                   0   \n",
       "1                  0                           0                   0   \n",
       "2                  0                           0                   0   \n",
       "3                  1                           0                   0   \n",
       "4                  0                           0                   0   \n",
       "\n",
       "   lead_time  arrival_year  arrival_month  arrival_date  market_segment_type  \\\n",
       "0          9          2018              1            14                    1   \n",
       "1        117          2018              7            29                    0   \n",
       "2        315          2018             12             2                    0   \n",
       "3         32          2018             12             1                    1   \n",
       "4        258          2018             10            16                    0   \n",
       "\n",
       "   repeated_guest  no_of_previous_cancellations  \\\n",
       "0               1                            11   \n",
       "1               0                             0   \n",
       "2               0                             0   \n",
       "3               0                             0   \n",
       "4               0                             0   \n",
       "\n",
       "   no_of_previous_bookings_not_canceled  avg_price_per_room  \\\n",
       "0                                     0               67.50   \n",
       "1                                     0               72.25   \n",
       "2                                     0               52.00   \n",
       "3                                     0               56.00   \n",
       "4                                     0              100.00   \n",
       "\n",
       "   no_of_special_requests  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14135fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: booking_status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc2e2d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "booking_status\n",
       "0    25596\n",
       "1    16504\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0481ff1",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "Based on the dataset provided, how many bookings are recorded where both the number of adults and the number of children are zero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1021221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original[(df_original['no_of_adults']==0) & (df_original['no_of_children']==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3c5ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_of_children\n",
       "2                 147\n",
       "0                  16\n",
       "1                   2\n",
       "3                   2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['no_of_adults']==0][['no_of_children']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0534c63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c84eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69a0d84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">id</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">no_of_special_requests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_month</th>\n",
       "      <th>1</th>\n",
       "      <th>7</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>8</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th colspan=\"2\" halign=\"left\">4</th>\n",
       "      <th>...</th>\n",
       "      <th>9</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>12</th>\n",
       "      <th>3</th>\n",
       "      <th colspan=\"2\" halign=\"left\">2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>booking_status</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42095</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42096</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42096.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42097</th>\n",
       "      <td>NaN</td>\n",
       "      <td>42097.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42099</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42099.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42100 rows Ã— 408 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                                       ...  \\\n",
       "arrival_month    1        7    12   10  8   6        10       9   4       ...   \n",
       "booking_status    0        0    0    1   1   0        0        0   1   0  ...   \n",
       "0               0.0      NaN  NaN  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "1               NaN      1.0  NaN  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "2               NaN      NaN  2.0  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "3               NaN      NaN  3.0  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "4               NaN      NaN  NaN  4.0 NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "...             ...      ...  ...  ...  ..  ..      ...      ...  ..  ..  ...   \n",
       "42095           NaN      NaN  NaN  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "42096           NaN      NaN  NaN  NaN NaN NaN      NaN  42096.0 NaN NaN  ...   \n",
       "42097           NaN  42097.0  NaN  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "42098           NaN      NaN  NaN  NaN NaN NaN      NaN      NaN NaN NaN  ...   \n",
       "42099           NaN      NaN  NaN  NaN NaN NaN  42099.0      NaN NaN NaN  ...   \n",
       "\n",
       "               no_of_special_requests                                       \n",
       "arrival_month                      9   5   6   5    12  3   2       3   1   \n",
       "booking_status                      1   1   1   0    1   0   1   0   1   1  \n",
       "0                                 NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "1                                 NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "2                                 NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "3                                 NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "4                                 NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "...                               ...  ..  ..  ..  ...  ..  ..  ..  ..  ..  \n",
       "42095                             NaN NaN NaN NaN  2.0 NaN NaN NaN NaN NaN  \n",
       "42096                             NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "42097                             NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "42098                             NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "42099                             NaN NaN NaN NaN  NaN NaN NaN NaN NaN NaN  \n",
       "\n",
       "[42100 rows x 408 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot(data=df_original ,columns=['arrival_month','booking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad25966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fce97a8e",
   "metadata": {},
   "source": [
    "#### Q2. Bookings per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "650bc8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>booking_status</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_month  booking_status  count\n",
       "0               1               0    747\n",
       "1               1               1     58\n",
       "2               2               0    884\n",
       "3               2               1    317\n",
       "4               3               0   1577\n",
       "5               3               1    624\n",
       "6               4               0   1924\n",
       "7               4               1   1082\n",
       "8               5               0   1955\n",
       "9               5               1   1337\n",
       "10              6               0   1945\n",
       "11              6               1   1411\n",
       "12              7               0   2463\n",
       "13              7               1   2218\n",
       "14              8               0   2722\n",
       "15              8               1   3041\n",
       "16              9               0   2981\n",
       "17              9               1   2167\n",
       "18             10               0   3530\n",
       "19             10               1   2923\n",
       "20             11               0   2029\n",
       "21             11               1    774\n",
       "22             12               0   2839\n",
       "23             12               1    552"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar1 = df.groupby(['arrival_month','booking_status'])['booking_status'].value_counts().reset_index()\n",
    "bar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb89ae2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='arrival_month', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEHCAYAAABfkmooAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfR0lEQVR4nO3dfbRVdb3v8feHh4RUTHm6yMYDGoby4EZ3XAozUseRvKZW2kArwSdMMc2exHPGKLPhyHs0UUu9Q01Fb6HeyvR6hSJOpPkQbWzLM0m4j2zkCGIZHgNl871/rN/W1WbtPdeWPdd++rzGWGPN9V2/Ob+/tZT9XfM35/xNRQRmZmat6dXRHTAzs87PxcLMzDK5WJiZWSYXCzMzy+RiYWZmmfp0dAfyMmjQoBg5cmRHd8PMrEtZtmzZqxExuHm82xaLkSNHUltb29HdMDPrUiT9R6m4h6HMzCyTi4WZmWVysTAzs0zd9phFKW+//TYNDQ3s2LGjo7vSpfXr14+qqir69u3b0V0xswrpUcWioaGB/fffn5EjRyKpo7vTJUUE27Zto6GhgVGjRnV0d8ysQnrUMNSOHTsYOHCgC8VekMTAgQO9d2bWw/SoYgG4ULQDf4dmPU9uxUJSP0lLJT0vaZWk76T41ZI2SapLj5OL1rlK0npJ6ySdVBQ/RtKK9N4t8l8rM7OKyvOYxU7g+Ih4Q1Jf4HeSFqT35kbEDcWNJR0JTAfGAgcDv5Z0eEQ0ArcDs4BngceBacACzMysInIrFlG4q9Ib6WXf9GjtTkunAQ9ExE7gRUnrgUmS6oEBEfEMgKT7gNNpp2JRX1/PKaecwsqVK/dqO01XjA8aNOgf4h/96Ed5+umn92rbWerr63n66ac5++yz26WdWVd1zDfuK7vtsuvPybEn3U+uxywk9ZZUB2wBFkXE79Nbl0paLuluSQem2HBgY9HqDSk2PC03j3cJeRcKKBSBn/zkJ+3WzsysuVyLRUQ0RkQ1UEVhL2EchSGlw4BqYDPw/dS81HGIaCW+B0mzJNVKqt26dWvZ/dy1axczZsxgwoQJnHHGGbz55pssXryYiRMnMn78eM477zx27twJ0GK8yd///nemTZvGnXfeCcB+++0HwJIlS5g6dSpnnHEGY8aM4fOf/zxNt7R9/PHHGTNmDMceeyyXXXYZp5xySot9/e1vf0t1dTXV1dVMnDiR7du3M2fOHJ588kmqq6uZO3cu9fX1fOxjH+Poo4/m6KOPfqdgNW937733cumll76z7VNOOYUlS5bQ2NjIzJkzGTduHOPHj2fu3Lllf5dm1j1V5GyoiPgrsASYFhGvpCKyG7gTmJSaNQAjilarAl5O8aoS8VJ57oiImoioGTx4j0kTW7Ru3TpmzZrF8uXLGTBgADfeeCMzZ87kwQcfZMWKFezatYvbb7+dHTt2lIw3eeONN/jUpz7F2WefzYUXXrhHnj/+8Y/cdNNNrF69mg0bNvDUU0+xY8cOLrroIhYsWMDvfvc7sorcDTfcwK233kpdXR1PPvkk/fv357rrruNjH/sYdXV1XHHFFQwZMoRFixbx3HPP8eCDD3LZZZcB7NGuJXV1dWzatImVK1eyYsUKzj333LK/SzPrnvI8G2qwpA+k5f7AicBaScOKmn0aaDpY8CgwXdI+kkYBo4GlEbEZ2C5pcjoL6hzgkfbs64gRI5gyZQoAX/jCF1i8eDGjRo3i8MMPB2DGjBk88cQTrFu3rmS8yWmnnca5557LOeeUHgudNGkSVVVV9OrVi+rqaurr61m7di2HHnroOxe4nXXWWa32dcqUKXz1q1/llltu4a9//St9+ux52Ontt9/mwgsvZPz48Zx55pmsXr26Td/HoYceyoYNG/jyl7/MwoULGTBgQJvWN7PuJ889i2HAbyQtB/5A4ZjFY8C/pdNglwOfAK4AiIhVwEPAamAhMDudCQVwMXAXsB74M+18JlS5Z+I2DRu1ZMqUKSxYsKDFdvvss887y71792bXrl2Z22xuzpw53HXXXfz9739n8uTJrF27do82c+fOZejQoTz//PPU1tby1ltvldxWnz592L179zuvmy60O/DAA3n++eeZOnUqt956KxdccEGb+mhm3U9uxSIilkfExIiYEBHjIuKaFP9iRIxP8VPTnkPTOtdGxGER8aGIWFAUr03bOCwiLo22/oXN8NJLL/HMM88AMH/+fE488UTq6+tZv349APfffz8f//jHGTNmTMl4k2uuuYaBAwdyySWXlJ17zJgxbNiwgfr6egAefPDBVtv/+c9/Zvz48Vx55ZXU1NSwdu1a9t9/f7Zv3/5Om9dff51hw4bRq1cv7r//fhobCzW3ebuRI0dSV1fH7t272bhxI0uXLgXg1VdfZffu3Xz2s5/lu9/9Ls8991zZn8fMuqcedwV3KUcccQTz5s1jwoQJvPbaa1xxxRXcc889nHnmmYwfP55evXrxpS99iX79+pWMF7vpppvYsWMH3/zmN8vK3b9/f2677TamTZvGsccey9ChQznggANabH/TTTcxbtw4jjrqKPr3788nP/lJJkyYQJ8+fTjqqKOYO3cul1xyCfPmzWPy5Mn86U9/Yt999wXYo92UKVMYNWoU48eP5+tf/zpHH300AJs2bWLq1KlUV1czc+ZMvve9773Hb9bMugu184/0TqOmpiaa3ylvzZo1HHHEER3Uo5a98cYb7LfffkQEs2fPZvTo0a0egO4MOut3aT2br7PYe5KWRURN87j3LDqBO++8k+rqasaOHcvrr7/ORRdd1NFdMjP7Bz1qivLO6oorrthjT+Kee+7h5ptv/ofYlClTuPXWWyvZNTMzwMWi0zr33HN9fYOZdRoehjIzs0wuFmZmlsnFwszMMvmYRTtqy2l75Sj31L6FCxdy+eWX09jYyAUXXMCcOXPatR9mZt6z6OIaGxuZPXs2CxYsYPXq1cyfP7/Nc0GZmWVxsejili5dygc/+EEOPfRQ3ve+9zF9+nQeeaRd51k0M3Ox6Oo2bdrEiBHvzuxeVVXFpk2bOrBHZtYduVh0caWmayl3Fl0zs3K5WHRxVVVVbNz47t1oGxoaOPjggzuwR2bWHblYdHEf/vCHeeGFF3jxxRd56623eOCBBzj11FM7ultm1s341Nl21BGzWPbp04cf/vCHnHTSSTQ2NnLeeecxduzYivfDzLo3F4tu4OSTT+bkk0/u6G6YWTfmYSgzM8vkYmFmZplcLMzMLJOLhZmZZcrtALekfsATwD4pz08j4tuSDgIeBEYC9cDnIuIvaZ2rgPOBRuCyiPhlih8D3Av0Bx4HLo/uevNws07ipWvGl932kG+tyLEn1hnkuWexEzg+Io4CqoFpkiYDc4DFETEaWJxeI+lIYDowFpgG3Capd9rW7cAsYHR6TMux32Zm1kxuexbpl/8b6WXf9AjgNGBqis8DlgBXpvgDEbETeFHSemCSpHpgQEQ8AyDpPuB0YEFefX+v2vJLrBzl/Fo777zzeOyxxxgyZAgrV65s1/xmZk1yPWYhqbekOmALsCgifg8MjYjNAOl5SGo+HNhYtHpDig1Py83jpfLNklQrqXbr1q3t+lk6q5kzZ7Jw4cKO7oaZdXO5XpQXEY1AtaQPAA9LGtdK81Kz30Ur8VL57gDuAKipqekRxzSOO+446uvrO7obZiW15YZgHTEDgpWvImdDRcRfKQw3TQNekTQMID1vSc0agBFFq1UBL6d4VYm4mZlVSG7FQtLgtEeBpP7AicBa4FFgRmo2A2i6U8+jwHRJ+0gaReFA9tI0VLVd0mQV5t4+p2gdMzOrgDyHoYYB89IZTb2AhyLiMUnPAA9JOh94CTgTICJWSXoIWA3sAmanYSyAi3n31NkFdMKD22bWtfjU4LbJ82yo5cDEEvFtwAktrHMtcG2JeC3Q2vEOMzPLkWedbUcd8evjrLPOYsmSJbz66qtUVVXxne98h/PPP7/i/TCz7s3FooubP39+R3fBzHoAzw1lZmaZvGdhZtYFtOWaFWj/61Z63J6F5x/ce/4OzXqeHlUs+vXrx7Zt2/zHbi9EBNu2baNfv34d3RUzq6AeNQxVVVVFQ0MDPWXeqLz069ePqqqq7IZm1m30qGLRt29fRo0a1dHdMDPrcnrUMJSZmb03LhZmZpapRw1DmfV0bTn98uH9c+yIdTneszAzs0wuFmZmlsnFwszMMrlYmJlZJhcLMzPL5GJhZmaZXCzMzCyTi4WZmWVysTAzs0y5FQtJIyT9RtIaSaskXZ7iV0vaJKkuPU4uWucqSeslrZN0UlH8GEkr0nu3SFJe/TYzsz3lOd3HLuBrEfGcpP2BZZIWpffmRsQNxY0lHQlMB8YCBwO/lnR4RDQCtwOzgGeBx4FpwIIc+25mZkVy27OIiM0R8Vxa3g6sAYa3ssppwAMRsTMiXgTWA5MkDQMGRMQzUbhr0X3A6Xn128zM9lSRYxaSRgITgd+n0KWSlku6W9KBKTYc2Fi0WkOKDU/LzeOl8sySVCup1jc4MjNrP7kXC0n7AT8DvhIRf6MwpHQYUA1sBr7f1LTE6tFKfM9gxB0RURMRNYMHD97brpuZWZLrFOWS+lIoFD+OiJ8DRMQrRe/fCTyWXjYAI4pWrwJeTvGqEnGzLq8tU4Yvu/6cHHti1ro8z4YS8CNgTUTcWBQfVtTs08DKtPwoMF3SPpJGAaOBpRGxGdguaXLa5jnAI3n128zM9pTnnsUU4IvACkl1KfYvwFmSqikMJdUDFwFExCpJDwGrKZxJNTudCQVwMXAv0J/CWVA+E8rMrIJyKxYR8TtKH294vJV1rgWuLRGvBca1X+/MzKwtfAW3mZllcrEwM7NMLhZmZpbJxcLMzDK5WJiZWSYXCzMzy+RiYWZmmVwszMwsk4uFmZllcrEwM7NMLhZmZpYp1ynKzaz9vHTN+LLbHvKtFTn2xHoi71mYmVkmFwszM8vkYSgz6xQ8zNa5ec/CzMwyuViYmVkmFwszM8vkYmFmZplcLMzMLFNuxULSCEm/kbRG0ipJl6f4QZIWSXohPR9YtM5VktZLWifppKL4MZJWpPdukaS8+m1mZnsqq1hIWlxOrJldwNci4ghgMjBb0pHAHGBxRIwGFqfXpPemA2OBacBtknqnbd0OzAJGp8e0cvptZmbto9XrLCT1A94PDEp7AE2/6AcAB7e2bkRsBjan5e2S1gDDgdOAqanZPGAJcGWKPxARO4EXJa0HJkmqBwZExDOpT/cBpwML2vA5zcza1THfuK9N7Zddf05OPamMrIvyLgK+QqEwLOPdYvE34NZyk0gaCUwEfg8MTYWEiNgsaUhqNhx4tmi1hhR7Oy03j5uZWYW0Wiwi4mbgZklfjogfvJcEkvYDfgZ8JSL+1srhhlJvRCvxUrlmURiu4pBDDml7Z83MrKSypvuIiB9I+igwsnidiGh1P0xSXwqF4scR8fMUfkXSsLRXMQzYkuINwIii1auAl1O8qkS8VD/vAO4AqKmpKVlQzMys7coqFpLuBw4D6oDGFA6gxWKRzlj6EbAmIm4seutRYAZwXXp+pCj+E0k3Uhj2Gg0sjYhGSdslTaYwjHUO8J72cqzracu4cFcfEzbrzMqdSLAGODIi2vJrfQrwRWCFpLoU+xcKReIhSecDLwFnAkTEKkkPAaspnEk1OyKaCtPFwL1AfwoHtn1w23Lh4mRWWrnFYiXw30hnN5UjIn5H6eMNACe0sM61wLUl4rXAuHJzW378x9SsZyq3WAwCVktaCuxsCkbEqbn0yszMOpVyi8XVeXbCzMw6t3LPhvpt3h0xM7POq9yzobbz7rUN7wP6Av8VEQPy6piZmXUe5e5Z7F/8WtLpwKQ8OmRmZp3Pe5p1NiJ+ARzfvl0xM7POqtxhqM8UvexF4boLXyFtZtZDlHs21KeKlncB9RRmiTUzsx6g3GMW5+bdETMz67zKvflRlaSHJW2R9Iqkn0mqyl7TzMy6g3IPcN9DYaK/gyncS+L/ppiZmfUA5RaLwRFxT0TsSo97gcE59svMzDqRcovFq5K+IKl3enwB2JZnx8zMrPMot1icB3wO+E8KM8+eAfigt5lZD1HuqbPfBWZExF8AJB0E3EChiJiZWTdX7p7FhKZCARARrwET8+mSmZl1NuUWi16SDmx6kfYsyt0rMTOzLq7cP/jfB56W9FMK03x8jhJ3tDMzs+6p3Cu475NUS2HyQAGfiYjVufbMzMw6jbKHklJxcIHoZHxPbDOrhPc0RbmZmfUsuRULSXenuaRWFsWulrRJUl16nFz03lWS1ktaJ+mkovgxklak926RpLz6bGZmpeW5Z3EvMK1EfG5EVKfH4wCSjgSmA2PTOrdJ6p3a3w7MAkanR6ltmplZjnIrFhHxBPBamc1PAx6IiJ0R8SKwHpgkaRgwICKeiYgA7gNOz6XDZmbWoo44ZnGppOVpmKrp2o3hwMaiNg0pNjwtN4+XJGmWpFpJtVu3bm3vfpuZ9ViVLha3A4cB1RTmmPp+ipc6DhGtxEuKiDsioiYiagYP9qS4ZmbtpaLFIiJeiYjGiNgN3AlMSm81ACOKmlYBL6d4VYm4mZlVUEWLRToG0eTTQNOZUo8C0yXtI2kUhQPZSyNiM7Bd0uR0FtQ5wCOV7LOZmeU4v5Ok+cBUYJCkBuDbwFRJ1RSGkuqBiwAiYpWkhyhc9LcLmB0RjWlTF1M4s6o/sCA9zMysgnIrFhFxVonwj1ppfy0l5puKiFpgXDt2zaxdvHTN+LLbHvKtFTn2xCx/voLbzMwyuViYmVkmFwszM8vkGxhZt+FjCGb58Z6FmZllcrEwM7NMLhZmZpbJxcLMzDK5WJiZWSYXCzMzy+RiYWZmmVwszMwsk4uFmZllcrEwM7NMLhZmZpbJxcLMzDK5WJiZWSYXCzMzy+Qpyi03bZkyHDxtuFln5j0LMzPLlFuxkHS3pC2SVhbFDpK0SNIL6fnAoveukrRe0jpJJxXFj5G0Ir13iyTl1WczMystzz2Le4FpzWJzgMURMRpYnF4j6UhgOjA2rXObpN5pnduBWcDo9Gi+TTMzy1luxSIingBeaxY+DZiXlucBpxfFH4iInRHxIrAemCRpGDAgIp6JiADuK1rHzMwqpNLHLIZGxGaA9DwkxYcDG4vaNaTY8LTcPF6SpFmSaiXVbt26tV07bmbWk3WWA9yljkNEK/GSIuKOiKiJiJrBgwe3W+fMzHq6SheLV9LQEul5S4o3ACOK2lUBL6d4VYm4mZlVUKWLxaPAjLQ8A3ikKD5d0j6SRlE4kL00DVVtlzQ5nQV1TtE6ZmZWIbldlCdpPjAVGCSpAfg2cB3wkKTzgZeAMwEiYpWkh4DVwC5gdkQ0pk1dTOHMqv7AgvQwM7MKyq1YRMRZLbx1QgvtrwWuLRGvBca1Y9fMzKyNOssBbjMz68Q8N1Q7O+Yb97Wp/bLrz8mpJ2Zm7cd7FmZmlsnFwszMMrlYmJlZJhcLMzPL5GJhZmaZfDaUmVkFtOXOkZ3xrpHeszAzs0zdfs/C1z2Yme0971mYmVkmFwszM8vkYmFmZplcLMzMLJOLhZmZZXKxMDOzTN3+1Fl7V1suCoLOeWGQmXUM71mYmVkmFwszM8vkYmFmZpk6pFhIqpe0QlKdpNoUO0jSIkkvpOcDi9pfJWm9pHWSTuqIPpuZ9WQdeYD7ExHxatHrOcDiiLhO0pz0+kpJRwLTgbHAwcCvJR0eEY2V77KZWdfQ3rPcdqZhqNOAeWl5HnB6UfyBiNgZES8C64FJle+emVnP1VHFIoBfSVomaVaKDY2IzQDpeUiKDwc2Fq3bkGJmZlYhHTUMNSUiXpY0BFgkaW0rbVUiFiUbFgrPLIBDDjlk73tpZmZAB+1ZRMTL6XkL8DCFYaVXJA0DSM9bUvMGYETR6lXAyy1s946IqImImsGDB+fVfTOzHqfixULSvpL2b1oG/hlYCTwKzEjNZgCPpOVHgemS9pE0ChgNLK1sr83MeraOGIYaCjwsqSn/TyJioaQ/AA9JOh94CTgTICJWSXoIWA3sAmb7TCgzs8qqeLGIiA3AUSXi24ATWljnWuDanLtmZmYt6EynzpqZWSflYmFmZplcLMzMLJOLhZmZZXKxMDOzTL5TXgdr78m+zMzy4D0LMzPL5GJhZmaZXCzMzCyTi4WZmWVysTAzs0wuFmZmlsnFwszMMrlYmJlZJhcLMzPL5GJhZmaZXCzMzCyTi4WZmWVysTAzs0wuFmZmlslTlDfjKcPNzPbUZfYsJE2TtE7SeklzOro/ZmY9SZcoFpJ6A7cCnwSOBM6SdGTH9srMrOfoEsUCmASsj4gNEfEW8ABwWgf3ycysx1BEdHQfMkk6A5gWERek118E/ntEXNqs3SxgVnr5IWDde0g3CHh1L7rbmfN158/mfM7nfO2T758iYnDzYFc5wK0SsT2qXETcAdyxV4mk2oio2ZttdNZ83fmzOZ/zOV+++brKMFQDMKLodRXwcgf1xcysx+kqxeIPwGhJoyS9D5gOPNrBfTIz6zG6xDBUROySdCnwS6A3cHdErMop3V4NY3XyfN35szmf8zlfjvm6xAFuMzPrWF1lGMrMzDqQi4WZmWVysUgk3S1pi6SVFcg1QtJvJK2RtErS5Tnn6ydpqaTnU77v5JmvKG9vSX+U9FgFctVLWiGpTlJtBfJ9QNJPJa1N/x0/kmOuD6XP1fT4m6Sv5JjvivT/yUpJ8yX1yytXynd5yrUqr89V6t+3pIMkLZL0Qno+MMdcZ6bPt1tSu54+20K+69P/m8slPSzpA3ubx8XiXfcC0yqUaxfwtYg4ApgMzM55+pKdwPERcRRQDUyTNDnHfE0uB9ZUIE+TT0REdYXOZb8ZWBgRY4CjyPFzRsS69LmqgWOAN4GH88glaThwGVATEeMonFAyPY9cKd844EIKszQcBZwiaXQOqe5lz3/fc4DFETEaWJxe55VrJfAZ4Il2ypGVbxEwLiImAH8CrtrbJC4WSUQ8AbxWoVybI+K5tLydwh+a4Tnmi4h4I73smx65ntkgqQr4H8BdeebpCJIGAMcBPwKIiLci4q8VSn8C8OeI+I8cc/QB+kvqA7yffK9pOgJ4NiLejIhdwG+BT7d3khb+fZ8GzEvL84DT88oVEWsi4r3MKPFe8/0qfZ8Az1K4Nm2vuFh0MEkjgYnA73PO01tSHbAFWBQRueYDbgK+CezOOU+TAH4laVma9iVPhwJbgXvSMNtdkvbNOWeT6cD8vDYeEZuAG4CXgM3A6xHxq7zyUfjFfZykgZLeD5zMP16Am6ehEbEZCj/ggCEVyltp5wEL9nYjLhYdSNJ+wM+Ar0TE3/LMFRGNaRijCpiUdv9zIekUYEtELMsrRwlTIuJoCjMTz5Z0XI65+gBHA7dHxETgv2i/IYwWpQtSTwX+T445DqTwi3sUcDCwr6Qv5JUvItYA/5PCsMlC4HkKw7TWDiT9K4Xv88d7uy0Xiw4iqS+FQvHjiPh5pfKm4ZIl5Ht8ZgpwqqR6CjMEHy/pf+eYj4h4OT1voTCePynHdA1AQ9He2U8pFI+8fRJ4LiJeyTHHicCLEbE1It4Gfg58NMd8RMSPIuLoiDiOwnDKC3nmK/KKpGEA6XlLhfJWhKQZwCnA56MdLqhzsegAkkRhvHtNRNxYgXyDm86GkNSfwh+EtXnli4irIqIqIkZSGDb594jI7deppH0l7d+0DPwzheGNXETEfwIbJX0ohU4AVueVr8hZ5DgElbwETJb0/vT/6QnkfJKCpCHp+RAKB4Hz/oxNHgVmpOUZwCMVyps7SdOAK4FTI+LNdtloRPhRKLrzKYzRvk3hl+P5OeY6lsIY+3KgLj1OzjHfBOCPKd9K4FsV/F6nAo/lnONQCsMXzwOrgH+twOeqBmrTd/oL4MCc870f2AYcUIHP9h0KPyZWAvcD++Sc70kKxfZ54ISccuzx7xsYSOEsqBfS80E55vp0Wt4JvAL8MufPth7YWPT35X/tbR5P92FmZpk8DGVmZplcLMzMLJOLhZmZZXKxMDOzTC4WZmaWycXCzMwyuViYZUhzP72nWYHT1OmD2rtPGTk/IOmSotdTKzFNvHVvLhZmRST1bv46Ii6IiEpcod1ePgBcktXIrC1cLKxHkfSLNDPtqqbZaSW9IekaSb8HPlLi9RJJNZIulvRvRduaKekHLW23jL6MTDeouSvd/OfHkk6U9FS6Ic+k1O6gtP3lkp6VNCHFr043vlkiaYOky9KmrwMOU+FGSden2H5692ZNP05TeZiVL++pA/zwozM9SFM6AP0pTGcxkMLUK58ratP89RKgBhgMrC+KLwCObWm76XU9MKiFvoykMCPoeAo/3JYBdwOiMPPrL1K7HwDfTsvHA3Vp+WrgaWAfYBCF6UD6pu2uLMozFXidwozDvYBnmvrthx/lPrxnYT3NZZKep3BDmBHAaKCRwgzATZq/BiAitgIbJE2WNBD4EPBUK9stx4sRsSIidlOY12pxRASwgsIffSjMJXZ/6sO/AwMlHZDe+38RsTMiXqUwa+rQFvIsjYiGlKeuaNtmZenT0R0wqxRJUynMuPuRiHhT0hKgH7AjIhqLmjZ/XexB4HMUJtp7OCKile2WY2fR8u6i17t5999nqSGjpknditdvpOV/0+W2MyvJexbWkxwA/CX9QR9D4f7nbfVzCrffPItC4Wiv7bbmCeDz8E7BezVav1nWdmD/du6D9XAuFtaTLAT6SFoOfJfCkFGbRMRfKEyn/U8RsbS9tpvhaqAmbf863r0HQ0t93AY8lQ6aX99aW7NyeYpyMzPL5D0LMzPL5INcZjlLZ04tLvHWCWnIyKzT8zCUmZll8jCUmZllcrEwM7NMLhZmZpbJxcLMzDL9f3T3CwJLm36bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=bar1,x='arrival_month',y='count',hue='booking_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c70e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55dc0952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>booking_status</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arrival_date</th>\n",
       "      <td>15.880645</td>\n",
       "      <td>15.937530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_month</th>\n",
       "      <td>7.576184</td>\n",
       "      <td>7.620456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_year</th>\n",
       "      <td>2017.806063</td>\n",
       "      <td>2017.934198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <td>99.869898</td>\n",
       "      <td>111.850132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>20978.607790</td>\n",
       "      <td>21159.446498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_time</th>\n",
       "      <td>79.485466</td>\n",
       "      <td>141.733883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market_segment_type</th>\n",
       "      <td>0.671199</td>\n",
       "      <td>0.817378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_adults</th>\n",
       "      <td>1.887092</td>\n",
       "      <td>1.972855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_children</th>\n",
       "      <td>0.139553</td>\n",
       "      <td>0.143480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <td>0.287271</td>\n",
       "      <td>0.002848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.001212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <td>0.708822</td>\n",
       "      <td>0.359125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <td>2.330950</td>\n",
       "      <td>2.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <td>0.853141</td>\n",
       "      <td>0.933471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repeated_guest</th>\n",
       "      <td>0.047586</td>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <td>0.036998</td>\n",
       "      <td>0.007029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_reserved</th>\n",
       "      <td>0.444366</td>\n",
       "      <td>0.404993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <td>0.217495</td>\n",
       "      <td>0.272843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "booking_status                                   0             1\n",
       "arrival_date                             15.880645     15.937530\n",
       "arrival_month                             7.576184      7.620456\n",
       "arrival_year                           2017.806063   2017.934198\n",
       "avg_price_per_room                       99.869898    111.850132\n",
       "id                                    20978.607790  21159.446498\n",
       "lead_time                                79.485466    141.733883\n",
       "market_segment_type                       0.671199      0.817378\n",
       "no_of_adults                              1.887092      1.972855\n",
       "no_of_children                            0.139553      0.143480\n",
       "no_of_previous_bookings_not_canceled      0.287271      0.002848\n",
       "no_of_previous_cancellations              0.031646      0.001212\n",
       "no_of_special_requests                    0.708822      0.359125\n",
       "no_of_week_nights                         2.330950      2.502000\n",
       "no_of_weekend_nights                      0.853141      0.933471\n",
       "repeated_guest                            0.047586      0.000667\n",
       "required_car_parking_space                0.036998      0.007029\n",
       "room_type_reserved                        0.444366      0.404993\n",
       "type_of_meal_plan                         0.217495      0.272843"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df,  columns='booking_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d3fdc2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>booking_status</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arrival_month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>884</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1577</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1924</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1955</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1945</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2463</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2722</td>\n",
       "      <td>3041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2981</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3530</td>\n",
       "      <td>2923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2029</td>\n",
       "      <td>774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2839</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "booking_status     0     1\n",
       "arrival_month             \n",
       "1                747    58\n",
       "2                884   317\n",
       "3               1577   624\n",
       "4               1924  1082\n",
       "5               1955  1337\n",
       "6               1945  1411\n",
       "7               2463  2218\n",
       "8               2722  3041\n",
       "9               2981  2167\n",
       "10              3530  2923\n",
       "11              2029   774\n",
       "12              2839   552"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df, index='arrival_month', columns='booking_status', aggfunc='size', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfbacc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "booking_status     0     1\n",
      "arrival_month             \n",
      "1                747    58\n",
      "2                884   317\n",
      "3               1577   624\n",
      "4               1924  1082\n",
      "5               1955  1337\n",
      "6               1945  1411\n",
      "7               2463  2218\n",
      "8               2722  3041\n",
      "9               2981  2167\n",
      "10              3530  2923\n",
      "11              2029   774\n",
      "12              2839   552\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "booking_status_counts = pd.pivot_table(df, index='arrival_month', columns='booking_status', aggfunc='size', fill_value=0) \n",
    "# Hint: Use 'arrival_month' and 'booking_status' columns and convert into pivot.\n",
    "\n",
    "print(booking_status_counts)\n",
    "\n",
    "# Plotting using the pivot table\n",
    "booking_status_counts.plot(kind='bar', figsize=(10, 7)) # Hint: use bar plot\n",
    "plt.title('Booking Status Count by Month')\n",
    "plt.xlabel('Arrival Month')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Booking Status')\n",
    "plt.tight_layout()  # Adjust layout to not cut off labels\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5557ce91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0d801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53229dd2",
   "metadata": {},
   "source": [
    "#### Q3. Datatime Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc8ae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(temp[['year', 'month', 'day']], errors='coerce')\n",
    "# ['year', 'month', 'day'] it has to be in this format(string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0222c4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                       0\n",
      "no_of_adults                             0\n",
      "no_of_children                           0\n",
      "no_of_weekend_nights                     0\n",
      "no_of_week_nights                        0\n",
      "type_of_meal_plan                        0\n",
      "required_car_parking_space               0\n",
      "room_type_reserved                       0\n",
      "lead_time                                0\n",
      "arrival_year                             0\n",
      "arrival_month                            0\n",
      "arrival_date                             0\n",
      "market_segment_type                      0\n",
      "repeated_guest                           0\n",
      "no_of_previous_cancellations             0\n",
      "no_of_previous_bookings_not_canceled     0\n",
      "avg_price_per_room                       0\n",
      "no_of_special_requests                   0\n",
      "booking_status                           0\n",
      "year                                    50\n",
      "month                                   50\n",
      "week                                    50\n",
      "day                                     50\n",
      "dayofweek                               50\n",
      "quarter                                 50\n",
      "dayofyear                               50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_arrival_date(data):\n",
    "    # Remove any pre-existing date columns that could conflict with the new transformations\n",
    "    data.drop(columns=['year', 'month', 'day'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Renaming columns for uniformity\n",
    "    temp = data.rename(columns={\n",
    "        'arrival_year': 'year',\n",
    "        'arrival_month': 'month',\n",
    "        'arrival_date': 'day'\n",
    "    })\n",
    "\n",
    "    # TODO: Creating a datetime column from the year, month, and day columns\n",
    "    data['date'] = pd.to_datetime(temp[['year', 'month', 'day']], errors='coerce')\n",
    "\n",
    "    # TODO: Extract date features\n",
    "    data['year'] = data['date'].dt.year\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['week'] = data['date'].dt.isocalendar().week.astype(float)\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['quarter'] = data['date'].dt.quarter\n",
    "    data['dayofyear'] = data['date'].dt.dayofyear\n",
    "\n",
    "    # Cleanup: Remove 'date' column after extracting necessary features\n",
    "    data.drop(columns='date', inplace=True)\n",
    "    return data\n",
    "\n",
    "# Test the function by applying it to a DataFrame 'df'\n",
    "new_processed_df = process_arrival_date(df)\n",
    "\n",
    "# Display missing values in the newly created columns to check for any NaN entries\n",
    "missing_values = new_processed_df.isna().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59b422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa540b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3127c849",
   "metadata": {},
   "source": [
    "####  Q5. Code Boosting Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0c4a6",
   "metadata": {},
   "source": [
    "#### Context:\n",
    "Gradient Boosting is a sequential learning technique in regression and classification that builds models progressively, using an ensemble of weak prediction models like decision trees. It focuses on minimizing errors primarily through the use of pseudo residuals.\n",
    "\n",
    "#### Task:\n",
    "Complete the Python code provided to implement a simple boosting algorithm using two Decision Tree classifiers. Then, determine the accuracy of the combined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fba4f406",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize weights\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(\u001b[43mx\u001b[49m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize weights\n",
    "np.ones(len(x)) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a103c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.ones(len(x)) / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "466373fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2bfb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fabeaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final combined prediction accuracy: 0.7140380047505939\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize weights\n",
    "weights = np.ones(len(X)) / len(X)\n",
    "\n",
    "# Train first weak learner\n",
    "dt1 = DecisionTreeClassifier(random_state=10, max_depth=1)\n",
    "dt1.fit(X, y)\n",
    "y_pred_1 = dt1.predict(X)\n",
    "\n",
    "# Update weights function\n",
    "def update_weights(y, y_pred, weights):\n",
    "    for i in range(len(weights)):\n",
    "        if y[i] != y_pred[i]: # Hint: If actual value is not same as predicted value.\n",
    "            weights[i] *= 1.5  # Increase the weight for misclassified instances\n",
    "        else:\n",
    "            weights[i] *= 0.5  # Decrease the weight for correctly classified instances\n",
    "    return weights / np.sum(weights)  # Normalize the weights\n",
    "\n",
    "# Apply first learner and update weights\n",
    "weights = update_weights(y, y_pred_1, weights) # Hint: update weights using actual and predicted.\n",
    "\n",
    "# Train second weak learner\n",
    "dt2 = DecisionTreeClassifier(random_state=10, max_depth=1)\n",
    "dt2.fit(X, y, sample_weight= weights)   # Utilize updated weights for learning for this sample_weight is used.\n",
    "y_pred_2 = dt2.predict(X)\n",
    "\n",
    "# Combine the weak learners' predictions\n",
    "# Assuming a simple average for combination of both the predictions\n",
    "final_prediction = np.round((y_pred_1 + y_pred_2) / 2.0).astype(int)\n",
    "\n",
    "# Calculate the accuracy\n",
    "final_accuracy = accuracy_score(y, final_prediction)\n",
    "print(f\"Final combined prediction accuracy: {final_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63c86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b5ade3d",
   "metadata": {},
   "source": [
    "#### Q7. Code Boosting resedual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e957a0",
   "metadata": {},
   "source": [
    "#### Context:\n",
    "Gradient Boosting is a sequential learning technique in regression and classification that builds models progressively, using an ensemble of weak prediction models like decision trees. It focuses on minimizing errors primarily through the use of pseudo residuals.\n",
    "\n",
    "#### Task:\n",
    "Complete the Python code provided below to implement a simple gradient boosting algorithm using pseudo residuals. You will fill in the missing parts of the code, run it, and determine the model's accuracy using mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb80d088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model accuracy: 0.7740567736555297\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = np.full(shape=y.shape, fill_value=np.mean(y))\n",
    "\n",
    "# Initialize pseudo residuals\n",
    "pseudo_residuals = y - y_pred\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Train first weak learner on pseudo residuals\n",
    "dt1 = DecisionTreeRegressor(max_depth=1, random_state=10)\n",
    "dt1.fit(X, pseudo_residuals)\n",
    "y_pred_1 = dt1.predict(X)\n",
    "\n",
    "# Update model predictions\n",
    "y_pred += y_pred_1 * learning_rate # Hint: use learning rate.\n",
    "\n",
    "# Calculate new pseudo residuals\n",
    "pseudo_residuals = y - y_pred\n",
    "\n",
    "# Train second weak learner on new pseudo residuals\n",
    "dt2 = DecisionTreeRegressor(max_depth=1, random_state=10)\n",
    "dt2.fit(X, pseudo_residuals)\n",
    "y_pred_2 = dt2.predict(X)\n",
    "\n",
    "# Update model predictions\n",
    "y_pred += y_pred_2* learning_rate\n",
    "\n",
    "# Calculate the accuracy using the mean squared error as a measure of accuracy for regression\n",
    "final_accuracy = 1 - mean_squared_error(y, y_pred)\n",
    "print(f\"Final model accuracy: {final_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32867476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a561347f",
   "metadata": {},
   "source": [
    "#### Q8. Boosting Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c39ee93",
   "metadata": {},
   "source": [
    "#### Context:\n",
    "Effectively preprocessing data can significantly impact the performance of machine learning models. This task involves evaluating how a Gradient Boosting Classifier performs on both an original dataset and the same dataset after preprocessing and missing value removal.\n",
    "\n",
    "#### Task:\n",
    "Implement a Gradient Boosting Classifier and assess its accuracy on both the original and a preprocessed version of a dataset. This will help determine the impact of preprocessing on model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c775de05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "      <th>booking_status</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>week</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>dayofyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>67.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>72.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>289.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42095</th>\n",
       "      <td>42095</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>140.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42096</th>\n",
       "      <td>42096</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>224.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42097</th>\n",
       "      <td>42097</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>96.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42098</th>\n",
       "      <td>42098</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>...</td>\n",
       "      <td>120.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42099</th>\n",
       "      <td>42099</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2017</td>\n",
       "      <td>...</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42100 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  no_of_adults  no_of_children  no_of_weekend_nights  \\\n",
       "0          0             2               0                     0   \n",
       "1          1             2               0                     1   \n",
       "2          2             2               0                     0   \n",
       "3          3             1               0                     0   \n",
       "4          4             2               0                     1   \n",
       "...      ...           ...             ...                   ...   \n",
       "42095  42095             3               0                     0   \n",
       "42096  42096             2               0                     0   \n",
       "42097  42097             2               0                     0   \n",
       "42098  42098             1               0                     0   \n",
       "42099  42099             2               0                     1   \n",
       "\n",
       "       no_of_week_nights  type_of_meal_plan  required_car_parking_space  \\\n",
       "0                      2                  1                           0   \n",
       "1                      2                  0                           0   \n",
       "2                      1                  0                           0   \n",
       "3                      2                  1                           0   \n",
       "4                      0                  0                           0   \n",
       "...                  ...                ...                         ...   \n",
       "42095                  4                  0                           0   \n",
       "42096                  3                  0                           0   \n",
       "42097                  2                  2                           0   \n",
       "42098                  3                  0                           0   \n",
       "42099                  1                  0                           0   \n",
       "\n",
       "       room_type_reserved  lead_time  arrival_year  ...  avg_price_per_room  \\\n",
       "0                       0          9          2018  ...               67.50   \n",
       "1                       0        117          2018  ...               72.25   \n",
       "2                       0        315          2018  ...               52.00   \n",
       "3                       0         32          2018  ...               56.00   \n",
       "4                       0        258          2018  ...              100.00   \n",
       "...                   ...        ...           ...  ...                 ...   \n",
       "42095                   1        160          2018  ...              140.00   \n",
       "42096                   0         34          2017  ...              224.67   \n",
       "42097                   0        292          2018  ...               96.00   \n",
       "42098                   0          5          2018  ...              120.00   \n",
       "42099                   1         40          2017  ...               65.00   \n",
       "\n",
       "       no_of_special_requests  booking_status    year  month  week   day  \\\n",
       "0                           0               0  2018.0    1.0   2.0  14.0   \n",
       "1                           0               0  2018.0    7.0  30.0  29.0   \n",
       "2                           0               0  2018.0   12.0  48.0   2.0   \n",
       "3                           0               0  2018.0   12.0  48.0   1.0   \n",
       "4                           0               1  2018.0   10.0  42.0  16.0   \n",
       "...                       ...             ...     ...    ...   ...   ...   \n",
       "42095                       2               1  2018.0   12.0  52.0  30.0   \n",
       "42096                       0               0  2017.0    9.0  38.0  23.0   \n",
       "42097                       0               0  2018.0    7.0  29.0  21.0   \n",
       "42098                       0               0  2018.0   11.0  45.0   9.0   \n",
       "42099                       0               0  2017.0   10.0  43.0  26.0   \n",
       "\n",
       "       dayofweek  quarter  dayofyear  \n",
       "0            6.0      1.0       14.0  \n",
       "1            6.0      3.0      210.0  \n",
       "2            6.0      4.0      336.0  \n",
       "3            5.0      4.0      335.0  \n",
       "4            1.0      4.0      289.0  \n",
       "...          ...      ...        ...  \n",
       "42095        6.0      4.0      364.0  \n",
       "42096        5.0      3.0      266.0  \n",
       "42097        5.0      3.0      202.0  \n",
       "42098        4.0      4.0      313.0  \n",
       "42099        3.0      4.0      299.0  \n",
       "\n",
       "[42100 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e7bfc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on original data: 0.8042755344418052\n",
      "Accuracy on processed data: 0.8128418549346017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TODO: Split original data\n",
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# TODO: Train Gradient Boosting Classifier on original data\n",
    "gbc_orig = GradientBoostingClassifier(random_state=10)\n",
    "gbc_orig.fit(X_train_orig, y_train_orig)\n",
    "pred_orig = gbc_orig.predict(X_test_orig)\n",
    "accuracy_orig = accuracy_score(y_test_orig, pred_orig)\n",
    "\n",
    "# Using the Processed dataset from the previous process_arrival_date\n",
    "new_df = new_processed_df.dropna()\n",
    "\n",
    "# TODO: Split processed data (ensure to select the same target variable 'y')\n",
    "X_train_proc, X_test_proc, y_train_proc, y_test_proc = train_test_split(new_df.drop(columns='booking_status', axis = 1), new_df['booking_status'], test_size=0.2, random_state=10)\n",
    "\n",
    "# TODO: Train Random Forest on processed data\n",
    "gbc_proc = GradientBoostingClassifier(random_state=10)\n",
    "gbc_proc.fit(X_train_proc, y_train_proc)\n",
    "pred_proc = gbc_proc.predict(X_test_proc)\n",
    "accuracy_proc = accuracy_score(y_test_proc, pred_proc)\n",
    "\n",
    "# Compare accuracies\n",
    "print(f\"Accuracy on original data: {accuracy_orig}\")\n",
    "print(f\"Accuracy on processed data: {accuracy_proc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1cd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1154146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08913749",
   "metadata": {},
   "source": [
    "### BOOSTING - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9546c",
   "metadata": {},
   "source": [
    "Context:\n",
    "Feature importance is a vital concept in machine learning, allowing data scientists to understand better which features contribute most to a model's predictions. Using a Gradient Boosting Classifier, this task focuses on determining the most influential feature in a dataset.\n",
    "\n",
    "Task:\n",
    "Train a Gradient Boosting Classifier on a given dataset and analyze the model to identify which feature is considered the most important based on the trained model.\n",
    "\n",
    "Question:\n",
    "After training the Gradient Boosting Classifier and examining the feature importance scores, which feature is considered most important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8986e8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important feature is: lead_time\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Initializing and training the Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier(random_state=10)\n",
    "clf.fit(X_train, y_train)         # Hint: Fit the clasifier with training data\n",
    "\n",
    "# TODO: Extracting feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Feature names\n",
    "features = np.array(X.columns)\n",
    "\n",
    "# TODO: Identifying the most important feature\n",
    "most_important_feature = features[np.argmax(feature_importances)]\n",
    "\n",
    "print(f\"The most important feature is: {most_important_feature}\")\n",
    "\n",
    "sns.barplot(y= features, x=feature_importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab155c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf26101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2810d7e9",
   "metadata": {},
   "source": [
    "#### Q2. Shrinkage Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411426b4",
   "metadata": {},
   "source": [
    "Context:\n",
    "The learning rate in gradient boosting models is a crucial parameter that scales the contribution of each tree. It can significantly affect model performance by controlling how quickly the model adapts to the complex underlying patterns in the data.\n",
    "\n",
    "Task:\n",
    "Your task is to find the optimal learning rate for a Gradient Boosting Classifier applied to the Reservation Cancellation Dataset. This involves comparing the performance of models trained with different learning rates.\n",
    "\n",
    "Question:\n",
    "After evaluating Gradient Boosting Classifier models with different learning rates on the Reservation Cancellation Dataset, which learning rate yielded the highest accuracy on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0244ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1  :  0.8042755344418052\n",
      "0.05  :  0.8005938242280285\n",
      "0.01  :  0.7859857482185273\n",
      "0.005  :  0.7357482185273159\n",
      "0.001  :  0.6086698337292161\n"
     ]
    }
   ],
   "source": [
    "# Define the learning rates to test\n",
    "learning_rates = [0.1, 0.05, 0.01, 0.005, 0.001]\n",
    "best_accuracy = 0\n",
    "best_learning_rate = 0\n",
    "\n",
    "# TODO: Train a model for each learning rate and evaluate its accuracy\n",
    "\n",
    "for lr in learning_rates: # Hint: iterate over all learning rates\n",
    "    model = GradientBoostingClassifier(learning_rate=lr, random_state=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(lr, \" : \", accuracy)\n",
    "\n",
    "    if accuracy > best_accuracy:  # Hint: add the necessary condition\n",
    "        best_accuracy = accuracy\n",
    "        best_learning_rate = lr\n",
    "\n",
    "print(f\"The best learning rate is: {best_learning_rate} with an accuracy of: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d41207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526e24b9",
   "metadata": {},
   "source": [
    "#### Q3. Boosting Max Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9e643",
   "metadata": {},
   "source": [
    "Context:\n",
    "The max_depth parameter in Gradient Boosting Classifier determines the maximum depth of the individual trees. Adjusting this parameter affects the model's complexity and its ability to capture the underlying patterns in the data, thus influencing performance.\n",
    "\n",
    "Task:\n",
    "Your task is to identify the optimal max_depth value that results in the highest accuracy for a Gradient Boosting Classifier applied to a dataset. This involves training and evaluating the classifier at various tree depths.\n",
    "\n",
    "Question:\n",
    "After training the Gradient Boosting Classifier at different tree depths and evaluating the models, which max_depth resulted in the highest accuracy on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e329db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKS WELL IN COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80f41fd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m       best_depth \u001b[38;5;241m=\u001b[39m d\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create the line plot\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Remove x-ticks\u001b[39;00m\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks([])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py:515\u001b[0m, in \u001b[0;36mlineplot\u001b[1;34m(data, x, y, hue, size, style, units, weights, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m color \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    513\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _default_color(ax\u001b[38;5;241m.\u001b[39mplot, hue, color, kwargs)\n\u001b[1;32m--> 515\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py:316\u001b[0m, in \u001b[0;36m_LinePlotter.plot\u001b[1;34m(self, ax, kws)\u001b[0m\n\u001b[0;32m    314\u001b[0m         lines\u001b[38;5;241m.\u001b[39mextend(ax\u001b[38;5;241m.\u001b[39mplot(unit_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], unit_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws))\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     lines \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mplot(sub_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], sub_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sub_vars:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupport for multi-dimensional indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1163\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing a Series with DataFrame is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported, use the appropriate DataFrame column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1161\u001b[0m     )\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key):\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;66;03m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1203\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_none(\u001b[38;5;241m*\u001b[39mkey):\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;66;03m# mpl compat if we look up e.g. ser[:, np.newaxis];\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;66;03m#  see tests.series.timeseries.test_mpl_compat_hack\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;66;03m# the asarray is needed to avoid returning a 2D DatetimeArray\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key])\n\u001b[1;32m-> 1203\u001b[0m     \u001b[43mdisallow_ndim_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:341\u001b[0m, in \u001b[0;36mdisallow_ndim_indexing\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mHelper function to disallow multi-dimensional indexing on 1D Series/Index.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03min GH#30588.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-dimensional indexing (e.g. `obj[:, None]`) is no longer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported. Convert to a numpy array before indexing instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = []\n",
    "best_depth = 0\n",
    "best_acc = 0\n",
    "\n",
    "# TODO: Train a model for each depth and evaluate its accuracy\n",
    "for d in range(1,15):\n",
    "    model = GradientBoostingClassifier(max_depth= d , random_state=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    acc.append(accuracy)\n",
    "\n",
    "    if accuracy > best_acc:   # Hint: add the necessary condition\n",
    "      best_acc = accuracy\n",
    "      best_depth = d\n",
    "\n",
    "\n",
    "# Create the line plot\n",
    "sns.lineplot(x=range(1, 15), y=acc)\n",
    "\n",
    "# Remove x-ticks\n",
    "plt.xticks([])\n",
    "\n",
    "# Add x-axis label\n",
    "plt.title(\"Find the max_depth\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Annotate the line at x = best_depth\n",
    "highest_acc = acc[best_depth - 1]  # Adjusting for zero-based indexing\n",
    "plt.axvline(x=best_depth, color='gray', linestyle='--')\n",
    "plt.text(best_depth + 0.2, highest_acc, f\"depth = {best_depth}\", verticalalignment='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3875cf96",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create the line plot\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Remove x-ticks\u001b[39;00m\n\u001b[0;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks([])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py:515\u001b[0m, in \u001b[0;36mlineplot\u001b[1;34m(data, x, y, hue, size, style, units, weights, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, estimator, errorbar, n_boot, seed, orient, sort, err_style, err_kws, legend, ci, ax, **kwargs)\u001b[0m\n\u001b[0;32m    512\u001b[0m color \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    513\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _default_color(ax\u001b[38;5;241m.\u001b[39mplot, hue, color, kwargs)\n\u001b[1;32m--> 515\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ax\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py:316\u001b[0m, in \u001b[0;36m_LinePlotter.plot\u001b[1;34m(self, ax, kws)\u001b[0m\n\u001b[0;32m    314\u001b[0m         lines\u001b[38;5;241m.\u001b[39mextend(ax\u001b[38;5;241m.\u001b[39mplot(unit_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], unit_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws))\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 316\u001b[0m     lines \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mplot(sub_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m], sub_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sub_vars:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupport for multi-dimensional indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1153\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_rows_with_mask(key)\n\u001b[1;32m-> 1153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1163\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing a Series with DataFrame is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported, use the appropriate DataFrame column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1161\u001b[0m     )\n\u001b[0;32m   1162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_values_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key):\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;66;03m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc[key]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1203\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39many_none(\u001b[38;5;241m*\u001b[39mkey):\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;66;03m# mpl compat if we look up e.g. ser[:, np.newaxis];\u001b[39;00m\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;66;03m#  see tests.series.timeseries.test_mpl_compat_hack\u001b[39;00m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;66;03m# the asarray is needed to avoid returning a 2D DatetimeArray\u001b[39;00m\n\u001b[0;32m   1202\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key])\n\u001b[1;32m-> 1203\u001b[0m     \u001b[43mdisallow_ndim_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:341\u001b[0m, in \u001b[0;36mdisallow_ndim_indexing\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mHelper function to disallow multi-dimensional indexing on 1D Series/Index.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03min GH#30588.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(result) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-dimensional indexing (e.g. `obj[:, None]`) is no longer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported. Convert to a numpy array before indexing instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "acc = []\n",
    "dep = []\n",
    "best_depth = 0\n",
    "best_acc = 0\n",
    "\n",
    "# Train a model for each depth and evaluate its accuracy\n",
    "for d in range(1,15):\n",
    "    model = GradientBoostingClassifier(max_depth= d , random_state=10)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    acc.append(accuracy)\n",
    "    dep.append(dep)\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "      best_acc = accuracy\n",
    "      best_depth = d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create the line plot\n",
    "sns.lineplot(x=range(1, 15), y=acc)\n",
    "\n",
    "# Remove x-ticks\n",
    "plt.xticks([])\n",
    "\n",
    "# Add x-axis label\n",
    "plt.title(\"Find the max_depth\")\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "# Annotate the line at x = 8\n",
    "highest_acc = acc[best_depth - 1]  # Adjusting for zero-based indexing\n",
    "plt.axvline(x=best_depth, color='gray', linestyle='--')\n",
    "plt.text(best_depth + 0.2, highest_acc, f\"depth = {best_depth}\", verticalalignment='center')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b348d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aec0bb94",
   "metadata": {},
   "source": [
    "#### Q4. Scaling in Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1176f843",
   "metadata": {},
   "source": [
    "Context:\n",
    "Feature scaling can significantly influence the performance of many machine learning algorithms, particularly those that are distance-based. However, decision trees and their ensembles (like Gradient Boosting) typically do not require feature scaling to perform effectively since they are not sensitive to the scale of the data.\n",
    "\n",
    "Task:\n",
    "Investigate whether scaling affects the performance of a Gradient Boosting Classifier by training two models: one with scaled features and one with original features.\n",
    "\n",
    "After training and evaluating both models, what will be the output of \n",
    "- accuracy_with_scaled_data \n",
    "- accuracy_without_scaled_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e761faf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_with_scaled = 0.8042755344418052\n",
      "accuracy_without_scaled = 0.8042755344418052\n",
      "Difference in accuracy = 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X_train and X_test are already defined\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# TODO: Fit on training data and transform it\n",
    "X_train_scaled = scaler.fit(X_train)\n",
    "\n",
    "# TODO: Transform the test data\n",
    "X_test_scaled = scaler.fit(X_test)\n",
    "\n",
    "# TODO: Train and test the GBC on the Scaled data\n",
    "model_with_scaled = GradientBoostingClassifier(random_state=10)\n",
    "model_with_scaled.fit(X_train, y_train)\n",
    "accuracy_with_scaled = accuracy_score(y_test, model_with_scaled.predict(X_test))\n",
    "\n",
    "# TODO: Train and test the GBC on the Original data (unscaled)\n",
    "model_without_scaled = GradientBoostingClassifier(random_state=10)\n",
    "model_without_scaled.fit(X_train, y_train)\n",
    "accuracy_without_scaled = accuracy_score(y_test, model_without_scaled.predict(X_test))\n",
    "\n",
    "print(f\"accuracy_with_scaled = {accuracy_with_scaled}\")\n",
    "print(f\"accuracy_without_scaled = {accuracy_without_scaled}\")\n",
    "\n",
    "print(f\"Difference in accuracy = {accuracy_with_scaled - accuracy_without_scaled}\") # TODO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a77e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39315d6c",
   "metadata": {},
   "source": [
    "#### Q5. Grid Search Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2c5dac",
   "metadata": {},
   "source": [
    "Context:\n",
    "Hyperparameter tuning is a critical step in optimizing machine learning models. Using GridSearchCV, you will tune the hyperparameters of a Gradient Boosting Classifier to find the combination that achieves the best performance on a given dataset.\n",
    "\n",
    "Task:\n",
    "Apply GridSearchCV to optimize a Gradient Boosting Classifier's hyperparameters on a split dataset. Determine the set of hyperparameters that results in the highest cross-validation performance.\n",
    "\n",
    "Question:\n",
    "After conducting the grid search, what are the optimal hyperparameters (Rank 1 parameters) discovered for the Gradient Boosting Classifier?\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 8],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15f0a35c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n",
      "Best parameters: {'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 300}\n",
      "Best cross-validation score: 0.8179334916864608\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100} Mean_score: 0.813687648456057 Rank: 8\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200} Mean_score: 0.8164786223277909 Rank: 6\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 300} Mean_score: 0.8169833729216152 Rank: 5\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 100} Mean_score: 0.8133907363420427 Rank: 9\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 200} Mean_score: 0.8174584323040379 Rank: 3\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 300} Mean_score: 0.8175475059382422 Rank: 2\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 100} Mean_score: 0.814459619952494 Rank: 7\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 200} Mean_score: 0.8170130641330167 Rank: 4\n",
      "Parameters:{'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 300} Mean_score: 0.8179334916864608 Rank: 1\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 100} Mean_score: 0.8133907363420427 Rank: 9\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 200} Mean_score: 0.8107482185273158 Rank: 15\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 2, 'n_estimators': 300} Mean_score: 0.8100653206650832 Rank: 18\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 100} Mean_score: 0.8132125890736341 Rank: 11\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 200} Mean_score: 0.811312351543943 Rank: 13\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 4, 'n_estimators': 300} Mean_score: 0.8106294536817102 Rank: 16\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 6, 'n_estimators': 100} Mean_score: 0.8130344418052257 Rank: 12\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 6, 'n_estimators': 200} Mean_score: 0.8109560570071259 Rank: 14\n",
      "Parameters:{'max_depth': 8, 'min_samples_split': 6, 'n_estimators': 300} Mean_score: 0.8103028503562946 Rank: 17\n",
      "GradientBoostingClassifier(max_depth=5, min_samples_split=6, n_estimators=300,\n",
      "                           random_state=10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Defining the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 8],\n",
    "    'min_samples_split': [2, 4, 6]\n",
    "}\n",
    "\n",
    "# Initializing the Gradient Boosting Classifier\n",
    "gbm = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "# Setting up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(gbm, param_grid, scoring = \"accuracy\", cv=2, n_jobs = -1, verbose = 1)\n",
    "\n",
    "\n",
    "# Fitting the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Printing the best parameters and the corresponding score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_}\")\n",
    "\n",
    "result = grid_search.cv_results_\n",
    "for i in range(len(result[\"params\"])):\n",
    "  print(f\"Parameters:{result['params'][i]} Mean_score: {result['mean_test_score'][i]} Rank: {result['rank_test_score'][i]}\")\n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c327148e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa81981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03198c2f",
   "metadata": {},
   "source": [
    "#### Q6. Best for Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fba4d",
   "metadata": {},
   "source": [
    "Context:\n",
    "After optimizing the parameters for a Gradient Boosting Classifier using GridSearchCV, it's crucial to validate the effectiveness of these parameters beyond just cross-validation scores, specifically on a held-out test set.\n",
    "\n",
    "Task:\n",
    "Train multiple Gradient Boosting Classifier models using the top 5 ranked parameter sets from a previous GridSearchCV optimization. Evaluate each model's performance on a separate test set to determine which set achieves the highest accuracy.\n",
    "\n",
    "Question:\n",
    "After evaluating the test set accuracies for Gradient Boosting Classifiers trained with the top 5 parameter sets, what is the rank of the best performing model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e041bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model number 1 with parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 200}: 0.8203087885985748\n",
      "\n",
      "Training model number 2 with parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 300}: 0.8214964370546318\n",
      "\n",
      "Training model number 3 with parameters: {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 100}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 100}: 0.8161520190023753\n",
      "\n",
      "Training model number 4 with parameters: {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 200}: 0.8203087885985748\n",
      "\n",
      "Training model number 5 with parameters: {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 300}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 300}: 0.8242280285035629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Sort the scores and parameters by rank\n",
    "sorted_indices = np.sort(result['rank_test_score'])\n",
    "top_indices = sorted_indices[:5]  # Hint: Get top 5 indices\n",
    "\n",
    "# TODO: Train a model for each of the top 5 parameter sets\n",
    "for i in top_indices:\n",
    "    params = result['params'][i]\n",
    "    print(f\"Training model number {i} with parameters: {params}\")\n",
    "\n",
    "    # TODO: Initialize and train the Gradient Boosting Classifier with the current set of parameters\n",
    "    model = GradientBoostingClassifier(**params, random_state = 10)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # TODo: Evaluate the model on the test set\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(f\"Test score with parameters {params}: {score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "175de99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model number 8 with parameters: {'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 300}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 300}: 0.8241092636579572\n",
      "\n",
      "Training model number 5 with parameters: {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 300}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 300}: 0.8242280285035629\n",
      "\n",
      "Training model number 4 with parameters: {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 200}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 200}: 0.8203087885985748\n",
      "\n",
      "Training model number 7 with parameters: {'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 200}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 6, 'n_estimators': 200}: 0.8207838479809976\n",
      "\n",
      "Training model number 2 with parameters: {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Test score with parameters {'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 300}: 0.8214964370546318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the scores and parameters by rank\n",
    "sorted_indices = np.argsort(result['rank_test_score'])\n",
    "top_indices = sorted_indices[:5]  # Get top 5 indices\n",
    "\n",
    "# Train a model for each of the top 5 parameter sets\n",
    "for i in top_indices:\n",
    "    params = result['params'][i]\n",
    "    print(f\"Training model number {i} with parameters: {params}\")\n",
    "\n",
    "    # Initialize and train the Gradient Boosting Classifier with the current set of parameters\n",
    "    model = GradientBoostingClassifier(**params, random_state = 10)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    score = model.score(X_test, y_test)\n",
    "    print(f\"Test score with parameters {params}: {score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13a31660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8242280285035629 > 0.8214964370546318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222378d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "814f58e5",
   "metadata": {},
   "source": [
    "#### Q7. Outliers in Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca670f8",
   "metadata": {},
   "source": [
    "Context:\n",
    "Outliers can significantly influence the performance of machine learning models, especially those not robust to extreme variations. Identifying outliers in training data helps in understanding their potential impact and deciding whether they should be treated or left as is.\n",
    "\n",
    "Task:\n",
    "Determine the number of outliers in the 'lead_time' feature of the training dataset, based on specified percentile thresholds.\n",
    "\n",
    "Question:\n",
    "Based on the 'lead-time' feature, how many outliers are present in the X_train set after splitting the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42778b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(334, 18)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Determine the 1th and 99th percentiles for 'lead_time'\n",
    "low_threshold, high_threshold = np.percentile(X_train['lead_time'], [1, 99])  # Hint: Use the numpy function to calculate percentiles. Remember to specify the percentile values as a list.\n",
    "\n",
    "# Identify the indices of rows that are not considered outliers\n",
    "not_outliers = X_train['lead_time'].between(low_threshold, high_threshold)   # Hint: Use a comparison operation to generate a boolean mask where values are between the low and high thresholds.\n",
    "\n",
    "# Count the number of outliers\n",
    "num_outliers = np.shape(X_train[~not_outliers])\n",
    "\n",
    "print(num_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9072cd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28506</th>\n",
       "      <td>28506</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>1547</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32528</th>\n",
       "      <td>32528</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>386</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18522</th>\n",
       "      <td>18522</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35897</th>\n",
       "      <td>35897</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>326</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158.40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31821</th>\n",
       "      <td>31821</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>2207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25235</th>\n",
       "      <td>25235</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34154</th>\n",
       "      <td>34154</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>332</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  no_of_adults  no_of_children  no_of_weekend_nights  \\\n",
       "28506  28506             2               0                     1   \n",
       "460      460             2               0                     0   \n",
       "1547    1547             1               0                     0   \n",
       "32528  32528             1               0                     2   \n",
       "18522  18522             2               0                     0   \n",
       "...      ...           ...             ...                   ...   \n",
       "35897  35897             2               2                     0   \n",
       "31821  31821             2               0                     0   \n",
       "2207    2207             2               0                     1   \n",
       "25235  25235             2               0                     1   \n",
       "34154  34154             2               0                     2   \n",
       "\n",
       "       no_of_week_nights  type_of_meal_plan  required_car_parking_space  \\\n",
       "28506                  2                  0                           0   \n",
       "460                    2                  2                           0   \n",
       "1547                   2                  2                           0   \n",
       "32528                  0                  0                           0   \n",
       "18522                  2                  2                           0   \n",
       "...                  ...                ...                         ...   \n",
       "35897                  5                  0                           0   \n",
       "31821                  2                  2                           0   \n",
       "2207                   3                  0                           0   \n",
       "25235                  2                  0                           0   \n",
       "34154                  3                  0                           0   \n",
       "\n",
       "       room_type_reserved  lead_time  arrival_year  arrival_month  \\\n",
       "28506                   0        418          2018              9   \n",
       "460                     0        377          2018             10   \n",
       "1547                    0        377          2018             10   \n",
       "32528                   0        386          2018             10   \n",
       "18522                   0        346          2017              9   \n",
       "...                   ...        ...           ...            ...   \n",
       "35897                   3        326          2018             12   \n",
       "31821                   0        346          2018              9   \n",
       "2207                    0        418          2018              9   \n",
       "25235                   0        418          2018              6   \n",
       "34154                   0        332          2018              9   \n",
       "\n",
       "       arrival_date  market_segment_type  repeated_guest  \\\n",
       "28506            26                    1               0   \n",
       "460              14                    0               0   \n",
       "1547             14                    0               0   \n",
       "32528            23                    0               0   \n",
       "18522            13                    1               0   \n",
       "...             ...                  ...             ...   \n",
       "35897            23                    1               0   \n",
       "31821            15                    0               0   \n",
       "2207             26                    0               0   \n",
       "25235            26                    0               0   \n",
       "34154            23                    1               0   \n",
       "\n",
       "       no_of_previous_cancellations  no_of_previous_bookings_not_canceled  \\\n",
       "28506                             0                                     0   \n",
       "460                               0                                     0   \n",
       "1547                              0                                     0   \n",
       "32528                             0                                     0   \n",
       "18522                             0                                     0   \n",
       "...                             ...                                   ...   \n",
       "35897                             0                                     0   \n",
       "31821                             0                                     0   \n",
       "2207                              0                                     0   \n",
       "25235                             0                                     0   \n",
       "34154                             0                                     0   \n",
       "\n",
       "       avg_price_per_room  no_of_special_requests  \n",
       "28506               75.00                       0  \n",
       "460                115.00                       1  \n",
       "1547                90.00                       0  \n",
       "32528              115.00                       0  \n",
       "18522              115.00                       1  \n",
       "...                   ...                     ...  \n",
       "35897              158.40                       2  \n",
       "31821              115.00                       1  \n",
       "2207                75.00                       0  \n",
       "25235               75.00                       0  \n",
       "34154               77.23                       1  \n",
       "\n",
       "[334 rows x 18 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[~not_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28b70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1cc29c68",
   "metadata": {},
   "source": [
    "#### Q8. Outliers in Boosting II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff65c8",
   "metadata": {},
   "source": [
    "Context:\n",
    "Outlier removal can potentially improve the performance of machine learning models by reducing noise and anomalies that can mislead the training process. This task involves assessing the effect of outlier removal on the accuracy of a Gradient Boosting Classifier.\n",
    "\n",
    "Task:\n",
    "Train a Gradient Boosting Classifier on a dataset from which outliers have been removed and compare its performance with a model trained on the original dataset.\n",
    "\n",
    "Question:\n",
    "After removing outliers based on the 'lead_time' feature and training a new Gradient Boosting Classifier, what is the impact on the model's accuracy when evaluated on X_test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce094b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset accuracy: 0.8042755344418052\n",
      "Dataset without outliers (based on 'lead_time') accuracy: 0.8065320665083135\n",
      "Removing outliers based on 'lead_time' improved the model's accuracy.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train on the original dataset\n",
    "original_clf = GradientBoostingClassifier(random_state=10)\n",
    "original_clf.fit(X_train, y_train)\n",
    "original_predictions = original_clf.predict(X_test)\n",
    "original_accuracy = accuracy_score(y_test, original_predictions)\n",
    "print(f\"Original dataset accuracy: {original_accuracy}\")\n",
    "\n",
    "# TODO: Filter the training data to remove outliers\n",
    "X_train_no_outliers = X_train[not_outliers]\n",
    "y_train_no_outliers = y_train[not_outliers]\n",
    "\n",
    "# Ensure there is data after removing outliers\n",
    "if len(X_train_no_outliers) == 0:\n",
    "    print(\"No data left after removing outliers based on 'lead_time'. Consider adjusting the percentile thresholds.\")\n",
    "else:\n",
    "    # TODO: Train on the dataset without outliers\n",
    "    clf_no_outliers = GradientBoostingClassifier(random_state=10)\n",
    "    clf_no_outliers.fit(X_train_no_outliers, y_train_no_outliers)\n",
    "    no_outliers_predictions = clf_no_outliers.predict(X_test)\n",
    "    no_outliers_accuracy = accuracy_score(y_test, no_outliers_predictions)\n",
    "    print(f\"Dataset without outliers (based on 'lead_time') accuracy: {no_outliers_accuracy}\")\n",
    "\n",
    "    # TODO: Compare the performance\n",
    "    if no_outliers_accuracy > original_accuracy:          # Hint: add the necessary condition\n",
    "        print(\"Removing outliers based on 'lead_time' improved the model's accuracy.\")\n",
    "    else:\n",
    "        print(\"Removing outliers based on 'lead_time' did not improve the model's accuracy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ac262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a2af23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57e5db4c",
   "metadata": {},
   "source": [
    "#### Q9. Loss in Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf29c1",
   "metadata": {},
   "source": [
    "Context:\n",
    "The choice of loss function in a Gradient Boosting Classifier can influence its performance. Typically, \"log loss\" is used for classification, but \"exponential\" loss, which leads to a model similar to AdaBoost, can also be used.\n",
    "\n",
    "Task:\n",
    "Evaluate the performance impact of different loss functions in a Gradient Boosting Classifier. Train two versions of the classifier on the same dataset: one using the default \"log loss\" loss function and another using the \"exponential\" loss function, then compare their accuracies.\n",
    "\n",
    "Question:\n",
    "How does the accuracy of the Gradient Boosting Classifier using the exponential loss function compare to the model using the default log_loss function when evaluated on X_test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2405f020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the 'log_loss' loss function: 0.8042755344418052\n",
      "Accuracy with the 'exponential' loss function: 0.8057007125890736\n",
      "The 'exponential' loss function model is more accurate on the test set.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train a Gradient Boosting Classifier using the default loss function (which is 'log_loss')\n",
    "clf_log_loss = GradientBoostingClassifier( random_state=10)       # default = 'log_loss'\n",
    "clf_log_loss.fit(X_train, y_train)\n",
    "predictions_log_loss = clf_log_loss.predict(X_test)\n",
    "accuracy_log_loss = accuracy_score(y_test, predictions_log_loss)\n",
    "print(f\"Accuracy with the 'log_loss' loss function: {accuracy_log_loss}\")\n",
    "\n",
    "# TODO: Train a Gradient Boosting Classifier using the 'exponential' loss function\n",
    "clf_exponential = GradientBoostingClassifier(loss='exponential', random_state=10)\n",
    "clf_exponential.fit(X_train, y_train)\n",
    "predictions_exponential = clf_exponential.predict(X_test)\n",
    "accuracy_exponential = accuracy_score(y_test, predictions_exponential)\n",
    "print(f\"Accuracy with the 'exponential' loss function: {accuracy_exponential}\")\n",
    "\n",
    "# Compare the accuracies\n",
    "if accuracy_exponential > accuracy_log_loss:\n",
    "    print(\"The 'exponential' loss function model is more accurate on the test set.\")\n",
    "elif accuracy_exponential < accuracy_log_loss:\n",
    "    print(\"The 'log_loss' loss function model is more accurate on the test set.\")\n",
    "else:\n",
    "    print(\"Both models have the same accuracy on the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f74e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a74a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "980cc1d0",
   "metadata": {},
   "source": [
    "#### Q10. Estimators in Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a7f127",
   "metadata": {},
   "source": [
    "Context:\n",
    "In Gradient Boosting, the number of weak learners (trees) is a crucial hyperparameter. It controls the complexity of the model and can significantly impact its performance. Observing how the model's accuracy evolves with the addition of more trees can provide insights into its learning dynamics and potential overfitting.\n",
    "\n",
    "Task:\n",
    "Train a series of Gradient Boosting Classifiers with an increasing number of estimators to evaluate how the addition of trees affects the test accuracy on a given dataset.\n",
    "\n",
    "Question:\n",
    "How does the addition of more weak learners (trees) affect the test accuracy of the Gradient Boosting Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "133b78d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 1 estimators: 0.6086698337292161\n",
      "Accuracy with 5 estimators: 0.7355106888361045\n",
      "Accuracy with 10 estimators: 0.7858669833729216\n",
      "Accuracy with 20 estimators: 0.7891923990498813\n",
      "Accuracy with 50 estimators: 0.8002375296912114\n",
      "Accuracy with 100 estimators: 0.8042755344418052\n",
      "Accuracy with 200 estimators: 0.8111638954869359\n",
      "Accuracy with 300 estimators: 0.8157957244655581\n",
      "Accuracy with 500 estimators: 0.8193586698337292\n",
      "Accuracy with 1000 estimators: 0.8258907363420428\n",
      "Accuracy with 1000 is more.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the number of estimators\n",
    "n_estimators_list = [1, 5, 10, 20, 50, 100, 200, 300, 500, 1000]\n",
    "test_accuracies = []\n",
    "\n",
    "# TODO: Train and evaluate the model with different numbers of weak learners\n",
    "for n_estimators in n_estimators_list:\n",
    "    clf = GradientBoostingClassifier(n_estimators=n_estimators, random_state=10)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    test_accuracies.append(accuracy)\n",
    "    print(f\"Accuracy with {n_estimators} estimators: {accuracy}\")\n",
    "max_accuracy = np.argmax(test_accuracies)\n",
    "print(\"Accuracy with\", n_estimators_list[max_accuracy],'is more.')\n",
    "\n",
    "# Plotting the test accuracies\n",
    "plt.plot(n_estimators_list, test_accuracies, marker='o')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy vs. Number of Estimators in Gradient Boosting')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6dc04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43334b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4b9767a",
   "metadata": {},
   "source": [
    "### ML: Other Ensemble Techniques - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcf14a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading xgboost-2.1.0-py3-none-win_amd64.whl (124.9 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from xgboost) (1.22.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd5a42c",
   "metadata": {},
   "source": [
    "#### Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709523ea",
   "metadata": {},
   "source": [
    "Context:\n",
    "XGBoost and Gradient Boosting Classifier (GBC) are both powerful ensemble machine learning algorithms based on boosting. While both aim to sequentially correct errors of weak learners, they are implemented differently and may have variations in performance, training speed, and memory usage.\n",
    "\n",
    "Task:\n",
    "Train both an XGBoost model and a Gradient Boosting Classifier on a dataset, then compare their training time and the file sizes of the saved models to determine which model is more efficient in terms of speed and storage.\n",
    "\n",
    "Question:\n",
    "After performing the training and saving the models, which of the following statements is correct regarding the performance and efficiency of XGBoost and GBC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa883278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost training time: 0.5157487392425537 seconds\n",
      "GBC training time: 7.058883905410767 seconds\n",
      "XGBoost model file size: 376128 bytes\n",
      "GBC model file size: 123990 bytes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import os\n",
    "\n",
    "# TODO: Train XGBoost\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_model = XGBClassifier(random_state=10)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_train_time = time.time() - start_time\n",
    "\n",
    "# Save XGBoost model\n",
    "with open('xgb_model.pkl', 'wb') as file:\n",
    "    pickle.dump(xgb_model, file)\n",
    "\n",
    "# TODO: Train GBC\n",
    "start_time = time.time()\n",
    "gbc_model = GradientBoostingClassifier(random_state=10)\n",
    "gbc_model.fit(X_train, y_train)\n",
    "gbc_train_time = time.time() - start_time\n",
    "\n",
    "# Save GBC model\n",
    "with open('gbc_model.pkl', 'wb') as file:\n",
    "    pickle.dump(gbc_model, file)\n",
    "\n",
    "# Output the training times\n",
    "print(f\"XGBoost training time: {xgb_train_time} seconds\")\n",
    "print(f\"GBC training time: {gbc_train_time} seconds\")\n",
    "\n",
    "# Check the file sizes\n",
    "xgb_file_size = os.path.getsize('xgb_model.pkl')\n",
    "gbc_file_size = os.path.getsize('gbc_model.pkl')\n",
    "\n",
    "# Output the file sizes\n",
    "print(f\"XGBoost model file size: {xgb_file_size} bytes\")\n",
    "print(f\"GBC model file size: {gbc_file_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cec020",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a821adf",
   "metadata": {},
   "source": [
    "#### Q2\n",
    "\n",
    "Context:\n",
    "Understanding how different boosting algorithms prioritize features and their prediction accuracy is crucial when choosing a model for deployment. This task involves evaluating XGBoost and Gradient Boosting Classifier (GBC) to determine which model performs better in terms of accuracy and how they compare in terms of identifying the most important features.\n",
    "\n",
    "Task:\n",
    "Train both XGBoost and a Gradient Boosting Classifier on the Reservation Booking Status dataset, evaluate their accuracy on the test set, and compare the most important features identified by each model.\n",
    "\n",
    "Question:\n",
    "After evaluating both models on the test set and assessing the most important features, which of the following statements is correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871ff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "875fa266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01231491, 0.02109817, 0.01387481, 0.01625015, 0.01604698,\n",
       "       0.0205303 , 0.12732057, 0.02194238, 0.08333495, 0.04457436,\n",
       "       0.03087396, 0.01300558, 0.21750169, 0.10644807, 0.        ,\n",
       "       0.01180213, 0.0398908 , 0.20319018], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bda7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost accuracy: 0.8273159144893112\n",
      "Most important feature in XGBoost: market_segment_type\n",
      "GBC accuracy: 0.8042755344418052\n",
      "Most important feature in GBC: lead_time\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate XGBoost on the test set\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "print(f\"XGBoost accuracy: {xgb_accuracy}\")\n",
    "\n",
    "# Determine the most important feature in XGBoost\n",
    "xgb_feature_importances = xgb_model.feature_importances_\n",
    "xgb_most_important_feature = X.columns[xgb_feature_importances.argmax()]\n",
    "print(f\"Most important feature in XGBoost: {xgb_most_important_feature}\")\n",
    "\n",
    "# Instantiate and train GBC\n",
    "gbc_model = GradientBoostingClassifier(random_state=10)\n",
    "gbc_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate GBC on the test set\n",
    "gbc_predictions = gbc_model.predict(X_test)\n",
    "gbc_accuracy = accuracy_score(y_test, gbc_predictions)\n",
    "print(f\"GBC accuracy: {gbc_accuracy}\")\n",
    "\n",
    "# Determine the most important feature in GBC\n",
    "gbc_feature_importances = gbc_model.feature_importances_\n",
    "gbc_most_important_feature = X.columns[gbc_feature_importances.argmax()]\n",
    "print(f\"Most important feature in GBC: {gbc_most_important_feature}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Feature importance for XGBoost\n",
    "xgb_importances = xgb_model.feature_importances_\n",
    "indices_xgb = np.argsort(xgb_importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances in XGBoost\")\n",
    "plt.barh(range(X_train.shape[1]), xgb_importances[indices_xgb], align=\"center\")\n",
    "plt.yticks(range(X_train.shape[1]), X.columns[indices_xgb])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance for GBC\n",
    "gbc_importances = gbc_model.feature_importances_\n",
    "indices_gbc = np.argsort(gbc_importances)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature importances in GBC\")\n",
    "plt.barh(range(X_train.shape[1]), gbc_importances[indices_gbc], align=\"center\")\n",
    "plt.yticks(range(X_train.shape[1]), X.columns[indices_gbc])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01c0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d7bde8e",
   "metadata": {},
   "source": [
    "#### Q3\n",
    "\n",
    "Context:\n",
    "XGBoost and LightGBM are both popular gradient boosting frameworks that are widely used due to their performance and speed. Comparing these two models on the same dataset can provide valuable insights into their efficiency and effectiveness in predictive accuracy.\n",
    "\n",
    "Task:\n",
    "Train both XGBoost and LightGBM models using default parameters on the Reservation Booking Status dataset. Record and compare their training times and accuracies.\n",
    "\n",
    "Question:\n",
    "After training both models and evaluating them on the test set, which of the following statements is true?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00de41e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbmNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading lightgbm-4.4.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from lightgbm) (1.22.4)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.4.0\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8144d0f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (2.2.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: dask[complete] in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (2022.2.1)\n",
      "Collecting dask[complete]\n",
      "  Downloading dask-2024.7.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (0.11.2)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (2022.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (2.0.0)\n",
      "Collecting click>=8.1\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Collecting partd>=1.4.0\n",
      "  Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (6.0)\n",
      "Collecting importlib-metadata>=4.13.0\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (21.3)\n",
      "Collecting lz4>=4.3.2\n",
      "  Downloading lz4-4.3.3-cp39-cp39-win_amd64.whl (99 kB)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (10.0.1)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from click>=8.1->dask[complete]) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.13.0->dask[complete]) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from packaging>=20.0->dask[complete]) (3.0.4)\n",
      "Requirement already satisfied: locket in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from partd>=1.4.0->dask[complete]) (0.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: bokeh>=2.4.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (2.4.2)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from dask[complete]) (2.11.3)\n",
      "Collecting dask-expr<1.2,>=1.1\n",
      "  Downloading dask_expr-1.1.7-py3-none-any.whl (241 kB)\n",
      "Collecting distributed==2024.7.0\n",
      "  Downloading distributed-2024.7.0-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: tblib>=1.6.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from distributed==2024.7.0->dask[complete]) (1.7.0)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from distributed==2024.7.0->dask[complete]) (1.26.9)\n",
      "Requirement already satisfied: tornado>=6.0.4 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from distributed==2024.7.0->dask[complete]) (6.1)\n",
      "Requirement already satisfied: psutil>=5.7.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from distributed==2024.7.0->dask[complete]) (5.8.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from distributed==2024.7.0->dask[complete]) (2.4.0)\n",
      "Collecting zict>=3.0.0\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "Collecting locket\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: msgpack>=1.0.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from distributed==2024.7.0->dask[complete]) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from bokeh>=2.4.2->dask[complete]) (4.1.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from bokeh>=2.4.2->dask[complete]) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from jinja2>=2.10.3->dask[complete]) (2.0.1)\n",
      "Installing collected packages: locket, partd, importlib-metadata, click, zict, dask, distributed, dask-expr, pyarrow-hotfix, lz4\n",
      "  Attempting uninstall: locket\n",
      "    Found existing installation: locket 0.2.1\n",
      "    Uninstalling locket-0.2.1:\n",
      "      Successfully uninstalled locket-0.2.1\n",
      "  Attempting uninstall: partd\n",
      "    Found existing installation: partd 1.2.0\n",
      "    Uninstalling partd-1.2.0:\n",
      "      Successfully uninstalled partd-1.2.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Uninstalling importlib-metadata-4.11.3:\n",
      "      Successfully uninstalled importlib-metadata-4.11.3\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: zict\n",
      "    Found existing installation: zict 2.0.0\n",
      "    Uninstalling zict-2.0.0:\n",
      "      Successfully uninstalled zict-2.0.0\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2022.2.1\n",
      "    Uninstalling dask-2022.2.1:\n",
      "      Successfully uninstalled dask-2022.2.1\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2022.2.1\n",
      "    Uninstalling distributed-2022.2.1:\n",
      "      Successfully uninstalled distributed-2022.2.1\n",
      "Successfully installed click-8.1.7 dask-2024.7.0 dask-expr-1.1.7 distributed-2024.7.0 importlib-metadata-8.0.0 locket-1.0.0 lz4-4.3.3 partd-1.4.2 pyarrow-hotfix-0.6 zict-3.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pandas \"dask[complete]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b599528d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SOURABH\\anaconda3\\lib\\site-packages\\dask\\dataframe\\_pyarrow_compat.py:15: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 10.0.1. Please consider upgrading.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13209, number of negative: 20471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 913\n",
      "[LightGBM] [Info] Number of data points in the train set: 33680, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392191 -> initscore=-0.438111\n",
      "[LightGBM] [Info] Start training from score -0.438111\n",
      "XGBoost training time: 0.4096870422363281 seconds\n",
      "XGBoost test accuracy: 0.8273159144893112\n",
      "LightGBM training time: 0.5505962371826172 seconds\n",
      "LightGBM test accuracy: 0.8184085510688837\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Train XGBoost\n",
    "start_time = time.time()\n",
    "xgb_model = XGBClassifier(random_state=10)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_train_time = time.time() - start_time\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
    "\n",
    "# Train LightGBM\n",
    "start_time = time.time()\n",
    "lgb_model = LGBMClassifier(random_state=10)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_train_time = time.time() - start_time\n",
    "lgb_predictions = lgb_model.predict(X_test)\n",
    "lgb_accuracy = accuracy_score(y_test, lgb_predictions)\n",
    "\n",
    "# Output the results\n",
    "print(f\"XGBoost training time: {xgb_train_time} seconds\")\n",
    "print(f\"XGBoost test accuracy: {xgb_accuracy}\")\n",
    "print(f\"LightGBM training time: {lgb_train_time} seconds\")\n",
    "print(f\"LightGBM test accuracy: {lgb_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60562c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bd9206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "310b63f2",
   "metadata": {},
   "source": [
    "#### Q5\n",
    "\n",
    "Context:\n",
    "Stacking and voting are two ensemble techniques used to improve machine learning predictions by combining the strengths of multiple models. This task will explore their efficacy by using them in a classification problem with several popular algorithms as base learners.\n",
    "\n",
    "Task:\n",
    "Implement a stacking ensemble model and a voting ensemble model using the same base learners on the Reservation Booking Status dataset. Compare the accuracy of these two ensemble methods on the test set.\n",
    "\n",
    "Question:\n",
    "After implementing and evaluating both the stacking ensemble model with XGBoost as the meta-learner and the voting ensemble model, how do their accuracies compare on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8093ce14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from mlxtend) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from mlxtend) (2.2.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from mlxtend) (3.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2022.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sourabh\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.23.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac6a7d90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13209, number of negative: 20471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 913\n",
      "[LightGBM] [Info] Number of data points in the train set: 33680, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392191 -> initscore=-0.438111\n",
      "[LightGBM] [Info] Start training from score -0.438111\n",
      "------------------------------\n",
      "Stacking Model Accuracy: 0.8149643705463183\n",
      "------------------------------\n",
      "[LightGBM] [Info] Number of positive: 13209, number of negative: 20471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 913\n",
      "[LightGBM] [Info] Number of data points in the train set: 33680, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392191 -> initscore=-0.438111\n",
      "[LightGBM] [Info] Start training from score -0.438111\n",
      "------------------------------\n",
      "Voting Model Accuracy: 0.8188836104513064\n",
      "------------------------------\n",
      "Voting ensemble is more accurate.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Initialize the base learners\n",
    "rf = RandomForestClassifier(random_state=10)\n",
    "gbc = RandomForestClassifier(random_state=10)\n",
    "xgb = XGBClassifier(random_state=10)\n",
    "lgbm = LGBMClassifier(random_state=10)\n",
    "ada = AdaBoostClassifier(random_state=10)\n",
    "\n",
    "# Initialize the Stacking Classifier using XGBoost as meta-learner\n",
    "stacking_clf = StackingClassifier(classifiers=[rf, gbc, lgbm, ada],\n",
    "                                  meta_classifier=xgb,\n",
    "                                  use_probas=True,\n",
    "                                  average_probas=False)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacking model\n",
    "stacking_predictions = stacking_clf.predict(X_test)\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_predictions)\n",
    "print(\"---\"*10)\n",
    "print(f\"Stacking Model Accuracy: {stacking_accuracy}\")\n",
    "print(\"---\"*10)\n",
    "\n",
    "# Initialize the Voting Classifier\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf), ('gbc', gbc), ('xgb', xgb), ('lgbm', lgbm), ('ada', ada)\n",
    "])\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the voting model\n",
    "voting_predictions = voting_clf.predict(X_test)\n",
    "voting_accuracy = accuracy_score(y_test, voting_predictions)\n",
    "print(\"---\"*10)\n",
    "print(f\"Voting Model Accuracy: {voting_accuracy}\")\n",
    "\n",
    "# Compare the accuracies\n",
    "print(\"---\"*10)\n",
    "if stacking_accuracy > voting_accuracy:\n",
    "    print(\"Stacking ensemble is more accurate.\")\n",
    "elif stacking_accuracy < voting_accuracy:\n",
    "    print(\"Voting ensemble is more accurate.\")\n",
    "else:\n",
    "    print(\"Both ensembles have the same accuracy.\")\n",
    "print(\"---\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec8c55b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad67d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc0e7a9c",
   "metadata": {},
   "source": [
    "#### Q6\n",
    "\n",
    "Context:\n",
    "Cascading models involve a sequential application of models where the output of one model feeds into the next. This technique can help focus a more complex model on the harder cases that a simpler model struggles with, potentially improving overall prediction accuracy.\n",
    "\n",
    "Task:\n",
    "Create a two-stage cascading boosting model where the first stage uses a LightGBM classifier to preprocess the data, and the second stage trains an XGBoost classifier on instances for which the first model had lower confidence. Evaluate the final model's performance on the entire test set.\n",
    "\n",
    "Question:\n",
    "After implementing the cascading model where the first stage is a LightGBM classifier and the second stage is an XGBoost classifier trained on filtered instances, what is the accuracy of the final XGBoost model on the entire test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ac02069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13209, number of negative: 20471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 913\n",
      "[LightGBM] [Info] Number of data points in the train set: 33680, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392191 -> initscore=-0.438111\n",
      "[LightGBM] [Info] Start training from score -0.438111\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = LGBMClassifier(random_state=10)\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Get the prediction probabilities for the training set and testing set\n",
    "lgb_train_prob = lgb_clf.predict_proba(X_train)[:, 1]   # Hint: we want probabilities not the predictions\n",
    "lgb_test_prob = lgb_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9063461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8420"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f7746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Answer should be this>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2443cc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13209, number of negative: 20471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 913\n",
      "[LightGBM] [Info] Number of data points in the train set: 33680, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392191 -> initscore=-0.438111\n",
      "[LightGBM] [Info] Start training from score -0.438111\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 18: given 33680",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m filter_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.75\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# TODO: Filter the DataFrame based on the LightGBM model's prediction probabilities above 75% and below 25%\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m filtered_train_df \u001b[38;5;241m=\u001b[39m X_train[\u001b[43m(\u001b[49m\u001b[43mlgb_train_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     14\u001b[0m filtered_y_train \u001b[38;5;241m=\u001b[39m y_train[(lgb_train_prob \u001b[38;5;241m<\u001b[39m filter_threshold) \u001b[38;5;241m|\u001b[39m (lgb_train_prob \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m filter_threshold))]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# TODO: Layer 2: Train a XGBoost classifier on the filtered training set\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2171\u001b[0m, in \u001b[0;36mNDFrame.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2167\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   2168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_ufunc__\u001b[39m(\n\u001b[0;32m   2169\u001b[0m     \u001b[38;5;28mself\u001b[39m, ufunc: np\u001b[38;5;241m.\u001b[39mufunc, method: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39minputs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m   2170\u001b[0m ):\n\u001b[1;32m-> 2171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arraylike\u001b[38;5;241m.\u001b[39marray_ufunc(\u001b[38;5;28mself\u001b[39m, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:276\u001b[0m, in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _standardize_out_kwarg(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# for binary ops, use our custom dunder methods\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m result \u001b[38;5;241m=\u001b[39m maybe_dispatch_ufunc_to_dunder_op(\u001b[38;5;28mself\u001b[39m, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py:82\u001b[0m, in \u001b[0;36mOpsMixin.__ror__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ror__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ror__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logical_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mror_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7910\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7907\u001b[0m axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[0;32m   7908\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[1;32m-> 7910\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_for_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   7912\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   7913\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:8141\u001b[0m, in \u001b[0;36mDataFrame._align_for_op\u001b[1;34m(self, other, axis, flex, level)\u001b[0m\n\u001b[0;32m   8139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   8140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m right\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 8141\u001b[0m         right \u001b[38;5;241m=\u001b[39m \u001b[43mto_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   8143\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m right\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   8144\u001b[0m         \u001b[38;5;66;03m# We need to pass dtype=right.dtype to retain object dtype\u001b[39;00m\n\u001b[0;32m   8145\u001b[0m         \u001b[38;5;66;03m#  otherwise we lose consistency with Index and array ops\u001b[39;00m\n\u001b[0;32m   8146\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:8133\u001b[0m, in \u001b[0;36mDataFrame._align_for_op.<locals>.to_series\u001b[1;34m(right)\u001b[0m\n\u001b[0;32m   8131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   8132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(right):\n\u001b[1;32m-> 8133\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   8134\u001b[0m             msg\u001b[38;5;241m.\u001b[39mformat(req_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(left\u001b[38;5;241m.\u001b[39mcolumns), given_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(right))\n\u001b[0;32m   8135\u001b[0m         )\n\u001b[0;32m   8136\u001b[0m     right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_constructor_sliced(right, index\u001b[38;5;241m=\u001b[39mleft\u001b[38;5;241m.\u001b[39mcolumns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   8137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m right\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to coerce to Series, length must be 18: given 33680"
     ]
    }
   ],
   "source": [
    "# TODO: Layer 1: Train a LightGBM classifier\n",
    "lgb_clf = LGBMClassifier(random_state=10)\n",
    "lgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Get the prediction probabilities for the training set and testing set\n",
    "lgb_train_prob = lgb_clf.predict_proba(X_train)[:, 1]   # Hint: we want probabilities not the predictions\n",
    "lgb_test_prob = lgb_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Filter out instances with confidence above 75% and below 25%\n",
    "filter_threshold = 0.75\n",
    "\n",
    "# TODO: Filter the DataFrame based on the LightGBM model's prediction probabilities above 75% and below 25%\n",
    "filtered_train_df = X_train[(lgb_train_prob < 0.75) | (X_train > (0.25))]\n",
    "filtered_y_train = y_train[(lgb_train_prob < filter_threshold) | (lgb_train_prob > (1 - filter_threshold))]\n",
    "\n",
    "# TODO: Layer 2: Train a XGBoost classifier on the filtered training set\n",
    "xgb_clf = XGBClassifier(random_state=10)\n",
    "xgb_clf.fit(filtered_train_df, filtered_y_train)\n",
    "\n",
    "# TODO: Make final predictions on the  test set with the XGBoost model\n",
    "final_predictions = xgb_clf.predict(X_test)\n",
    "final_accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Final Model Accuracy on Filtered Test Set: {final_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316e65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <Given answer in assessment>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43a4bd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13209, number of negative: 20471\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 913\n",
      "[LightGBM] [Info] Number of data points in the train set: 33680, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.392191 -> initscore=-0.438111\n",
      "[LightGBM] [Info] Start training from score -0.438111\n",
      "Cascading Model Accuracy: 0.8224465558194775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split your data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Layer 1: Train a LightGBM model\n",
    "lgb = lgb.LGBMClassifier(random_state=10)\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "# Use the predictions of the first layer as features for the second layer\n",
    "X_train_layer2 = np.column_stack((X_train, lgb.predict_proba(X_train)[:, 1]))\n",
    "X_test_layer2 = np.column_stack((X_test, lgb.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# Layer 2: Train a Gradient Boosting Classifier\n",
    "gbc = GradientBoostingClassifier(random_state=10)\n",
    "gbc.fit(X_train_layer2, y_train)\n",
    "\n",
    "# Evaluate the final model\n",
    "final_predictions = gbc.predict(X_test_layer2)\n",
    "final_accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(f\"Cascading Model Accuracy: {final_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65259018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33680, 19)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_layer2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3063e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33680, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4413eabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54237183, 0.45762817],\n",
       "       [0.88975698, 0.11024302],\n",
       "       [0.84727033, 0.15272967],\n",
       "       ...,\n",
       "       [0.97970163, 0.02029837],\n",
       "       [0.20375458, 0.79624542],\n",
       "       [0.5924415 , 0.4075585 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "92d64bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33680, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.predict_proba(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714bc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c2ad730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.45762817, 0.11024302, 0.15272967, ..., 0.02029837, 0.79624542,\n",
       "       0.4075585 ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.predict_proba(X_train)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "19c09dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>no_of_adults</th>\n",
       "      <th>no_of_children</th>\n",
       "      <th>no_of_weekend_nights</th>\n",
       "      <th>no_of_week_nights</th>\n",
       "      <th>type_of_meal_plan</th>\n",
       "      <th>required_car_parking_space</th>\n",
       "      <th>room_type_reserved</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_date</th>\n",
       "      <th>market_segment_type</th>\n",
       "      <th>repeated_guest</th>\n",
       "      <th>no_of_previous_cancellations</th>\n",
       "      <th>no_of_previous_bookings_not_canceled</th>\n",
       "      <th>avg_price_per_room</th>\n",
       "      <th>no_of_special_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6483</th>\n",
       "      <td>6483</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30903</th>\n",
       "      <td>30903</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33845</th>\n",
       "      <td>33845</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26092</th>\n",
       "      <td>26092</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17299</th>\n",
       "      <td>17299</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28712</th>\n",
       "      <td>28712</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>9289</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16241</th>\n",
       "      <td>16241</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>9372</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17673</th>\n",
       "      <td>17673</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10461 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  no_of_adults  no_of_children  no_of_weekend_nights  \\\n",
       "6483    6483             2               0                     0   \n",
       "30903  30903             1               0                     1   \n",
       "33845  33845             2               1                     2   \n",
       "26092  26092             1               0                     0   \n",
       "17299  17299             1               0                     1   \n",
       "...      ...           ...             ...                   ...   \n",
       "28712  28712             3               0                     2   \n",
       "9289    9289             3               0                     2   \n",
       "16241  16241             2               0                     0   \n",
       "9372    9372             2               0                     0   \n",
       "17673  17673             2               0                     2   \n",
       "\n",
       "       no_of_week_nights  type_of_meal_plan  required_car_parking_space  \\\n",
       "6483                   2                  0                           0   \n",
       "30903                  1                  0                           0   \n",
       "33845                  0                  0                           0   \n",
       "26092                  1                  0                           0   \n",
       "17299                  3                  0                           0   \n",
       "...                  ...                ...                         ...   \n",
       "28712                  2                  0                           0   \n",
       "9289                   0                  0                           0   \n",
       "16241                  4                  0                           0   \n",
       "9372                   4                  0                           0   \n",
       "17673                  2                  0                           0   \n",
       "\n",
       "       room_type_reserved  lead_time  arrival_year  arrival_month  \\\n",
       "6483                    4         24          2018              7   \n",
       "30903                   0         19          2018             10   \n",
       "33845                   0         61          2018              7   \n",
       "26092                   0         99          2018              2   \n",
       "17299                   0        118          2018              6   \n",
       "...                   ...        ...           ...            ...   \n",
       "28712                   3         17          2018             10   \n",
       "9289                    1         96          2018              7   \n",
       "16241                   0        183          2018             10   \n",
       "9372                    1         92          2018              8   \n",
       "17673                   0        166          2018              8   \n",
       "\n",
       "       arrival_date  market_segment_type  repeated_guest  \\\n",
       "6483              1                    1               0   \n",
       "30903            19                    2               0   \n",
       "33845            25                    1               0   \n",
       "26092            30                    2               0   \n",
       "17299            15                    0               0   \n",
       "...             ...                  ...             ...   \n",
       "28712             2                    1               0   \n",
       "9289              3                    1               0   \n",
       "16241            29                    1               0   \n",
       "9372              2                    1               0   \n",
       "17673             5                    1               0   \n",
       "\n",
       "       no_of_previous_cancellations  no_of_previous_bookings_not_canceled  \\\n",
       "6483                              0                                     0   \n",
       "30903                             0                                     0   \n",
       "33845                             0                                     0   \n",
       "26092                             0                                     0   \n",
       "17299                             0                                     0   \n",
       "...                             ...                                   ...   \n",
       "28712                             0                                     0   \n",
       "9289                              0                                     0   \n",
       "16241                             0                                     0   \n",
       "9372                              0                                     0   \n",
       "17673                             0                                     0   \n",
       "\n",
       "       avg_price_per_room  no_of_special_requests  \n",
       "6483               142.00                       0  \n",
       "30903              159.00                       0  \n",
       "33845              121.50                       1  \n",
       "26092               81.00                       0  \n",
       "17299              110.00                       0  \n",
       "...                   ...                     ...  \n",
       "28712              153.62                       1  \n",
       "9289               146.70                       1  \n",
       "16241               80.10                       2  \n",
       "9372               150.30                       1  \n",
       "17673               99.45                       1  \n",
       "\n",
       "[10461 rows x 18 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[(lgb.predict_proba(X_train)[:, 1] < 0.75) & (lgb.predict_proba(X_train)[:, 1] > 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4817d8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33680"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lgb_train_prob > 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057ae16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b6b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a27c5bb2",
   "metadata": {},
   "source": [
    "#### Q2\n",
    "\n",
    "Given the data (X and y), use sklearn's stacking for the regression model for firstly, training all the models individually, and then, training the stacked regressor.\n",
    "\n",
    "In this question, we are using KNN and decision tree for the level 0 models and linear regression for the meta-model.\n",
    "\n",
    "Note: All required dependencies have been imported already.\n",
    "\n",
    "Two lists are taken as input X and y\n",
    "\n",
    "The mean of cross-validation scores for each model is printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6c3b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[-0.12289022551864817, -0.9357694342590688], [0.5129298204180088, -0.29809283510271567], [0.48851814653749703, -0.07557171302105573], [-0.2678880796260159, 0.530355466738186], [-1.1006191772129212, 1.1447237098396141], [-1.4441138054295894, -0.5044658629464512], [0.8389834138745049, 0.9311020813035573], [-0.17242820755043575, -0.8778584179213718], [0.2300947353643834, 0.7620111803120247], [-0.671246130836819, -0.01266459891890136], [-0.6871727001195994, -0.8452056414987196], [0.31903909605709857, -0.2493703754774101], [-0.691660751725309, -0.39675352685597737], [-0.7471582937508376, 1.6924546010277466], [1.6598021771098705, 0.7420441605773356], [-0.6200008439481293, 0.6980320340722189], [-0.3752849500901142, -0.6387304074542224], [-0.3062040126283718, 0.8279746426072462], [-0.3224172040135075, -0.38405435466841564], [1.74481176421648, -0.7612069008951028], [0.8654076293246785, -2.3015386968802827], [0.12015895248162915, 0.6172031097074192], [-0.22232814261035927, -0.20075806892999745], [-0.7543979409966528, 1.2528681552332879], [1.6243453636632417, -0.6117564136500754], [-1.1173103486352778, 0.23441569781709215], [-0.5281717522634557, -1.0729686221561705], [0.9015907205927955, 0.5024943389018682], [0.4234943540641129, 0.07734006834855942], [0.3001703199558275, -0.35224984649351865], [-0.19183555236161492, -0.8876289640848363], [0.04221374671559283, 0.5828152137158222], [0.16003706944783047, 0.8761689211162249], [0.19829972012676975, 0.11900864580745882], [1.131629387451427, 1.5198168164221988], [2.1855754065331614, -1.3964963354881377], [1.462107937044974, -2.060140709497654], [1.198917879901507, 0.18515641748394385], [0.1865613909882843, 0.4100516472082563], [0.19091548466746602, 2.100255136478842], [1.1337694423354374, -1.0998912673140309], [-0.6706622862890306, 0.3775637863209194], [-1.1425181980221402, -0.3493427224128775], [-0.3438536755710756, 0.04359685683424694], [0.9008559492644118, -0.6837278591743331], [-0.2088942333747781, 0.5866231911821976], [0.05080775477602897, -0.6369956465693534], [0.31563494724160523, -2.022201215824003], [0.12182127099143693, 1.1294839079119197], [0.2855873252542588, 0.8851411642707281]] \n",
    "y = [-46.34457583853899, 29.89203815293042, 36.57670478050099, -1.0548543507733465, -44.34760203047087, -136.23585513274503, 103.81048050179038, -48.10275508775748, 48.11630577045144, -54.62694386929622, -88.13212433240432, 16.15177140411067, -71.37438371388818, 5.53682925172843, 162.66695252711517, -23.210158588999548, -55.040032571465225, 7.3813358866864425, -40.945038837952694, 111.31738238616813, -19.52961992002634, 33.79973612507111, -25.64394667923562, -12.417030626190087, 107.41448375249622, -81.08909809239485, -84.1858887757812, 92.17168168963711, 37.248421360886816, 10.59831841709924, -49.78340567852572, 26.043717785494916, 46.98000533279682, 20.673696974050426, 150.21975566743365, 122.28638742509285, 38.00737094940657, 104.00861175886935, 31.03679755941446, 96.99313535634106, 48.849928674845266, -39.47151812217092, -105.88279350591996, -26.092669988864273, 46.22449353100841, 5.979177298086575, -20.791632075145184, -52.9535092860866, 53.64827578648195, 57.32065154495446]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfefa2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cart 0.641\n",
      "knn 0.830\n",
      "stacking 0.811\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "\n",
    "X = X\n",
    "y = y\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('knn', KNeighborsRegressor()))\n",
    "\tlevel0.append(('cart', DecisionTreeRegressor()))\n",
    "\n",
    "\t# define meta learner model, it'll be a linear regression model\n",
    "\tlevel1 = LinearRegression()\n",
    "\t\n",
    "\t# define the stacking ensemble for regression with level0 and meta model\n",
    "\tmodel = StackingRegressor(estimators=level0, final_estimator=level1)\n",
    "\t\n",
    "\treturn model\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\t\n",
    "\t#intialize the object for knn for regression\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\t\n",
    "\t#intialize the object for decision tree for regression\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\t\n",
    "\treturn models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\n",
    "    #initialize RepeatedKfold object with k = 10 and 3 repetitions\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3)\n",
    "\t\n",
    "\t# evaluate the model using r2 and the above cross validation strategy\n",
    "\tscores = cross_val_score(model, X, y, scoring='r2', cv = cv)\n",
    "\t\n",
    "\treturn scores\n",
    "\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in sorted(models.items()):\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tprint('%s %.3f' % (name, np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
